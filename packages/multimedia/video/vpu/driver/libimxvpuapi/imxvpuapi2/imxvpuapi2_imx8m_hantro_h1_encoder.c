#include <assert.h>
#include <string.h>
#include <stdlib.h>
#include <inttypes.h>

#include <config.h>
#include "imxvpuapi2.h"
#include "imxvpuapi2_priv.h"

#include "vp8encapi.h"
#include "h264encapi.h"

#include <imxdmabuffer/imxdmabuffer.h>




/******************************************************/
/******* MISCELLANEOUS STRUCTURES AND FUNCTIONS *******/
/******************************************************/


/* Define the stream buffer size to be able to hold one big
 * uncompressed YUV 4:4:4 frame, plus some extra headroom.
 * This is more than what the encoder will ever produce,
 * which is needed to prevent the encoder from running out
 * of stream buffer memory. */
#define VPU_ENC_MIN_REQUIRED_STREAM_BUFFER_SIZE  (1920*1088*3 + 262144)
#define STREAM_BUFFER_PHYSADDR_ALIGNMENT         (0x10)
#define STREAM_BUFFER_SIZE_ALIGNMENT             (1024)
#define FRAME_WIDTH_ALIGNMENT                    (16)
#define FRAME_HEIGHT_ALIGNMENT                   (2)


typedef struct
{
	ImxVpuApiEncReturnCodes (*open_encoder)(ImxVpuApiEncoder *base, void **h1_encoder);
	void (*close_encoder)(void *h1_encoder);

	ImxVpuApiEncReturnCodes (*start_stream)(void *h1_encoder, size_t *output_size);

	ImxVpuApiEncReturnCodes (*encode_frame)(void *h1_encoder, ImxVpuApiFrameType frame_type, size_t *encoded_frame_size, ImxVpuApiFrameType *encoded_frame_type, ImxVpuApiEncOutputCodes *output_code);
	void (*get_encoded_data)(void *h1_encoder, ImxVpuApiEncodedFrame *encoded_frame);

	void (*flush)(void *h1_encoder);
}
HantroH1EncoderFunctions;

static HantroH1EncoderFunctions const h1_vp8_encoder_functions;

static HantroH1EncoderFunctions const h1_h264_encoder_functions;

static char const * imx_vpu_api_h1_encoder_2state_mode_to_string(uint32_t mode)
{
	switch (mode)
	{
		case 0: return "disabled";
		case 1: return "enabled";
		default: return "<unknown>";
	}
}

static char const * imx_vpu_api_h1_encoder_3state_mode_to_string(uint32_t mode)
{
	switch (mode)
	{
		case 0: return "disabled";
		case 1: return "adaptive";
		case 2: return "enabled";
		default: return "<unknown>";
	}
}



/*******************************************************/
/******* PUBLIC ENCODER STRUCTURES AND FUNCTIONS *******/
/*******************************************************/


struct _ImxVpuApiEncoder
{
	/* Specific H1 encoder to use (VP8 or h.264). */
	void *h1_encoder;
	HantroH1EncoderFunctions const *h1_encoder_functions;

	/* Stream buffer. Holds data coming from the encoder. */
	ImxDmaBuffer *stream_buffer;
	/* Due to the way the Hantro H1 encoder operates, we have to map
	 * the stream buffer for as long as the encoder is open.
	 * The mapped virtual address is stored in this field. */
	uint8_t *stream_buffer_virtual_address;
	/* Physical address of the stream buffer. Stored here to avoid
	 * redundant imx_dma_buffer_get_physical_address() calls. */
	imx_physical_address_t stream_buffer_physical_address;
	/* Size of the stream buffer, in bytes. Stored here to avoid
	 * redundant imx_dma_buffer_get_size() calls. */
	size_t stream_buffer_size;

	/* Copy of the open_params passed to imx_vpu_api_enc_open(). */
	ImxVpuApiEncOpenParams open_params;

	/* Stream information that is generated by imx_vpu_api_enc_open(). */
	ImxVpuApiEncStreamInfo stream_info;

	/* Set to TRUE if intra refresh is enabled, either because the open_params
	 * IMX_VPU_API_ENC_OPEN_PARAMS_FLAG_USE_INTRA_REFRESH flag is set, or because
	 * the open_params min_intra_refresh_mb_count is nonzero. The exact
	 * intra refresh method is up to the specific encoder. For example,
	 * the h.264 encoder has GDR (Gradual Decoder Refresh) for that. */
	BOOL use_intra_refresh;

	/* How many macroblocks are present in a row, a column, and in the whole
	 * frame. Macroblocks are 16x16 pixel blocks. These metrics include partial
	 * macroblocks. For example, when the frame height is 1080, which is not
	 * an integer multiple of 16, num_macroblocks_per_column is 68, not 67,
	 * because 1080 / 16 = 67.5, and the number is always rounded up to
	 * include the partial macroblock. */
	size_t num_macroblocks_per_row;
	size_t num_macroblocks_per_column;
	size_t num_macroblocks_per_frame;

	/* DEPRECATED. This is kept here for backwards compatibility. */
	BOOL drain_mode_enabled;

	BOOL encoded_frame_is_sync_point;

	/* h.264 SPS/PPS header data generated by the encoder's start_stream
	 * function. This is prepended to the main frame data if
	 * must_prepend_header_data is set to TRUE. */
	uint8_t *header_data;
	size_t header_data_size;

	/* TRUE if a header generated by the encoder is to be prepended to the
	 * data of the encoded frame that will be output next. This is needed
	 * for setting the has_header field in ImxVpuApiEncEncodedFrame and
	 * is used in imx_vpu_api_enc_get_encoded_frame() to check if the
	 * header_data needs to be prepended, which happens at the beginning
	 * of the stream. */
	BOOL must_prepend_header_data;

	/* TRUE if the next frame shall be forcibly encoded as an I/IDR frame.
	 * This is used after flushing to make sure the next frame is an
	 * I/IDR frame. */
	BOOL force_IDR_frame;

	/* How many bytes of encoded frame data are currently stored in
	 * the stream buffer. This number is always less than or equal to
	 * stream_buffer_size. */
	size_t num_bytes_in_stream_buffer;

	/* The raw frame that is staged for encoding.
	 * (Staging is done by imx_vpu_api_enc_push_raw_frame().) */
	ImxVpuApiRawFrame staged_raw_frame;
	/* Physical address of the staged raw frame. Stored here to avoid
	 * redundant imx_dma_buffer_get_physical_address() calls. */
	imx_physical_address_t staged_raw_frame_physical_address;
	/* TRUE if a frame is staged, FALSE otherwise (the staged frame
	 * fields above are invalid if this is FALSE). */
	BOOL staged_raw_frame_set;

	/* TRUE is an encoded frame is available, FALSE otherwise.
	 * If set to FALSE, then the fields below about the encoded frame
	 * are invalid. */
	BOOL encoded_frame_available;

	/* Context, PTS, DTS copied from the input raw frame. */
	void *encoded_frame_context;
	uint64_t encoded_frame_pts, encoded_frame_dts;
	/* What encoded frame type the input raw frame was encoded into.
	 * Filled in imx_vpu_api_enc_encode(). */
	ImxVpuApiFrameType encoded_frame_type;
	/* Size of the resulting encoded frame, in bytes. If a header
	 * was prepended, then its size is included in this. This value
	 * is used for setting the data_size field of the
	 * ImxVpuApiEncEncodedFrame structure when getting the encoded
	 * frame with imx_vpu_api_enc_get_encoded_frame(). */
	size_t encoded_frame_data_size;
};



/* Static, invariant global & compression format information. */

static ImxVpuApiCompressionFormat const enc_supported_compression_formats[] =
{
	IMX_VPU_API_COMPRESSION_FORMAT_VP8,
	IMX_VPU_API_COMPRESSION_FORMAT_H264
};

static ImxVpuApiEncGlobalInfo const enc_global_info = {
	.flags = IMX_VPU_API_ENC_GLOBAL_INFO_FLAG_HAS_ENCODER | IMX_VPU_API_ENC_GLOBAL_INFO_FLAG_SEMI_PLANAR_FRAMES_SUPPORTED | IMX_VPU_API_ENC_GLOBAL_INFO_FLAG_FULLY_PLANAR_FRAMES_SUPPORTED |
		IMX_VPU_API_ENC_GLOBAL_INFO_FLAG_ENCODER_SUPPORTS_RGB_FORMATS,
	.hardware_type = IMX_VPU_API_HARDWARE_TYPE_HANTRO,
	.min_required_stream_buffer_size = VPU_ENC_MIN_REQUIRED_STREAM_BUFFER_SIZE,
	.required_stream_buffer_physaddr_alignment = STREAM_BUFFER_PHYSADDR_ALIGNMENT,
	.required_stream_buffer_size_alignment = STREAM_BUFFER_SIZE_ALIGNMENT,
	.supported_compression_formats = enc_supported_compression_formats,
	.num_supported_compression_formats = sizeof(enc_supported_compression_formats) / sizeof(ImxVpuApiCompressionFormat)
};

ImxVpuApiEncGlobalInfo const * imx_vpu_api_enc_get_global_info(void)
{
	return &enc_global_info;
}


static ImxVpuApiColorFormat const enc_supported_basic_color_formats[] =
{
	IMX_VPU_API_COLOR_FORMAT_FULLY_PLANAR_YUV420_8BIT,
	IMX_VPU_API_COLOR_FORMAT_SEMI_PLANAR_YUV420_8BIT,
	IMX_VPU_API_COLOR_FORMAT_PACKED_YUV422_UYVY_8BIT,
	IMX_VPU_API_COLOR_FORMAT_PACKED_YUV422_YUYV_8BIT,
	IMX_VPU_API_COLOR_FORMAT_RGB565,
	IMX_VPU_API_COLOR_FORMAT_BGR565,
	IMX_VPU_API_COLOR_FORMAT_RGB444,
	IMX_VPU_API_COLOR_FORMAT_ARGB4444,
	IMX_VPU_API_COLOR_FORMAT_ARGB1555,
	IMX_VPU_API_COLOR_FORMAT_RGBA8888,
	IMX_VPU_API_COLOR_FORMAT_BGRA8888
};

static ImxVpuApiVP8SupportDetails const enc_vp8_support_details = {
	.parent = {
		.min_width = 132, .max_width = 1920,
		.min_height = 96, .max_height = 1088,
		.supported_color_formats = enc_supported_basic_color_formats,
		.num_supported_color_formats = sizeof(enc_supported_basic_color_formats) / sizeof(ImxVpuApiColorFormat),
		.min_quantization = 0, .max_quantization = 127
	},

	.supported_profiles = (1 << IMX_VPU_API_VP8_PROFILE_0)
	                    | (1 << IMX_VPU_API_VP8_PROFILE_1)
	                    | (1 << IMX_VPU_API_VP8_PROFILE_2)
	                    | (1 << IMX_VPU_API_VP8_PROFILE_3)
};

static ImxVpuApiH264SupportDetails const enc_h264_support_details = {
	.parent = {
		.min_width = 132, .max_width = 1920,
		.min_height = 96, .max_height = 1088,
		.supported_color_formats = enc_supported_basic_color_formats,
		.num_supported_color_formats = sizeof(enc_supported_basic_color_formats) / sizeof(ImxVpuApiColorFormat),
		.min_quantization = 1, .max_quantization = 51
	},

	.max_constrained_baseline_profile_level = IMX_VPU_API_H264_LEVEL_5_1,
	.max_baseline_profile_level = IMX_VPU_API_H264_LEVEL_UNDEFINED,
	.max_main_profile_level = IMX_VPU_API_H264_LEVEL_5_1,
	.max_high_profile_level = IMX_VPU_API_H264_LEVEL_5_1,
	.max_high10_profile_level = IMX_VPU_API_H264_LEVEL_UNDEFINED,

	.flags = 0
};


ImxVpuApiCompressionFormatSupportDetails const * imx_vpu_api_enc_get_compression_format_support_details(ImxVpuApiCompressionFormat compression_format)
{
	switch (compression_format)
	{
		case IMX_VPU_API_COMPRESSION_FORMAT_VP8:
			return (ImxVpuApiCompressionFormatSupportDetails const *)(&enc_vp8_support_details);

		case IMX_VPU_API_COMPRESSION_FORMAT_H264:
			return (ImxVpuApiCompressionFormatSupportDetails const *)(&enc_h264_support_details);

		default:
			return NULL;
	}

	return NULL;
}


void imx_vpu_api_enc_set_default_open_params(ImxVpuApiCompressionFormat compression_format, ImxVpuApiColorFormat color_format, size_t frame_width, size_t frame_height, ImxVpuApiEncOpenParams *open_params)
{
	assert(open_params != NULL);

	open_params->frame_width = frame_width;
	open_params->frame_height = frame_height;
	open_params->compression_format = compression_format;
	open_params->color_format = color_format;
	open_params->bitrate = 256;
	open_params->quantization = 0;
	open_params->gop_size = 16;
	open_params->min_intra_refresh_mb_count = 0;
	open_params->closed_gop_interval = 0;
	open_params->frame_rate_numerator = 25;
	open_params->frame_rate_denominator = 1;

	switch (compression_format)
	{
		case IMX_VPU_API_COMPRESSION_FORMAT_H264:
			open_params->format_specific_open_params.h264_open_params.profile = IMX_VPU_API_H264_PROFILE_CONSTRAINED_BASELINE;
			open_params->format_specific_open_params.h264_open_params.level = IMX_VPU_API_H264_LEVEL_UNDEFINED;
			open_params->format_specific_open_params.h264_open_params.enable_access_unit_delimiters = 0;
			break;
		case IMX_VPU_API_COMPRESSION_FORMAT_VP8:
			open_params->format_specific_open_params.vp8_open_params.profile = IMX_VPU_API_VP8_PROFILE_0;
			open_params->format_specific_open_params.vp8_open_params.partition_count = IMX_VPU_API_ENC_VP8_PARTITION_COUNT_1;
			open_params->format_specific_open_params.vp8_open_params.error_resilient_mode = FALSE;
			break;

		default:
			break;
	}
}


ImxVpuApiEncReturnCodes imx_vpu_api_enc_open(ImxVpuApiEncoder **encoder, ImxVpuApiEncOpenParams *open_params, ImxDmaBuffer *stream_buffer)
{
	int err;
	ImxVpuApiEncReturnCodes ret = IMX_VPU_API_ENC_RETURN_CODE_OK;
	ImxVpuApiFramebufferMetrics *fb_metrics;
	BOOL semi_planar;
	size_t stream_buffer_size;

	assert(encoder != NULL);
	assert(open_params != NULL);
	assert(stream_buffer != NULL);


	/* Check that the allocated stream buffer is big enough */
	{
		stream_buffer_size = imx_dma_buffer_get_size(stream_buffer);
		if (stream_buffer_size < VPU_ENC_MIN_REQUIRED_STREAM_BUFFER_SIZE) 
		{
			IMX_VPU_API_ERROR("stream buffer size is %zu bytes; need at least %zu bytes", stream_buffer_size, (size_t)VPU_ENC_MIN_REQUIRED_STREAM_BUFFER_SIZE);
			return IMX_VPU_API_ENC_RETURN_CODE_INSUFFICIENT_STREAM_BUFFER_SIZE;
		}
	}


	/* Validate the open params. */

	if (open_params->gop_size == 0)
	{
		IMX_VPU_API_ERROR("GOP size must be at least 1");
		return IMX_VPU_API_ENC_RETURN_CODE_INVALID_PARAMS;
	}


	/* Allocate encoder instance. */
	*encoder = malloc(sizeof(ImxVpuApiEncoder));
	assert((*encoder) != NULL);


	/* Set default encoder values. */
	memset(*encoder, 0, sizeof(ImxVpuApiEncoder));


	/* Map the stream buffer. We need to keep it mapped always so we can
	 * keep updating it. It is mapped as readwrite so we can shift data
	 * inside it later with memmove() if necessary.
	 * Mapping this with IMX_DMA_BUFFER_MAPPING_FLAG_MANUAL_SYNC since
	 * the stream buffer stays mapped until the encoder is closed, and
	 * we do copy encoded data into the stream buffer. Also see the
	 * imx_dma_buffer_start_sync_session() / imx_dma_buffer_stop_sync_session()
	 * calls in imx_vpu_api_enc_push_encoded_frame(). */
	(*encoder)->stream_buffer_virtual_address = imx_dma_buffer_map(stream_buffer, IMX_DMA_BUFFER_MAPPING_FLAG_WRITE | IMX_DMA_BUFFER_MAPPING_FLAG_READ | IMX_DMA_BUFFER_MAPPING_FLAG_MANUAL_SYNC, &err);
	if ((*encoder)->stream_buffer_virtual_address == NULL)
	{
			IMX_VPU_API_ERROR("mapping stream buffer to virtual address space failed: %s (%d)", strerror(err), err);
			ret = IMX_VPU_API_ENC_RETURN_CODE_DMA_MEMORY_ACCESS_ERROR;
			goto cleanup;
	}

	(*encoder)->stream_buffer_physical_address = imx_dma_buffer_get_physical_address(stream_buffer);
	(*encoder)->stream_buffer_size = stream_buffer_size;
	(*encoder)->stream_buffer = stream_buffer;


	/* Make a copy of the open_params for later use. */
	(*encoder)->open_params = *open_params;


	fb_metrics = &((*encoder)->stream_info.frame_encoding_framebuffer_metrics);

	fb_metrics->actual_frame_width = open_params->frame_width;
	fb_metrics->actual_frame_height = open_params->frame_height;
	fb_metrics->aligned_frame_width = IMX_VPU_API_ALIGN_VAL_TO(fb_metrics->actual_frame_width, FRAME_WIDTH_ALIGNMENT);
	fb_metrics->aligned_frame_height = IMX_VPU_API_ALIGN_VAL_TO(fb_metrics->actual_frame_height, FRAME_HEIGHT_ALIGNMENT);

	semi_planar = imx_vpu_api_is_color_format_semi_planar(open_params->color_format);

	switch (open_params->color_format)
	{
		case IMX_VPU_API_COLOR_FORMAT_FULLY_PLANAR_YUV420_8BIT:
		case IMX_VPU_API_COLOR_FORMAT_SEMI_PLANAR_YUV420_8BIT:
			fb_metrics->y_stride = fb_metrics->aligned_frame_width;
			fb_metrics->y_size = fb_metrics->y_stride * fb_metrics->aligned_frame_height;
			fb_metrics->uv_stride = fb_metrics->y_stride / 2;
			fb_metrics->uv_size = fb_metrics->y_size / 4;
			break;

		case IMX_VPU_API_COLOR_FORMAT_PACKED_YUV422_UYVY_8BIT:
		case IMX_VPU_API_COLOR_FORMAT_PACKED_YUV422_YUYV_8BIT:
			fb_metrics->y_stride = fb_metrics->aligned_frame_width * 2;
			fb_metrics->y_size = fb_metrics->y_stride * fb_metrics->aligned_frame_height;
			fb_metrics->uv_stride = 0;
			fb_metrics->uv_size = 0;
			break;

		case IMX_VPU_API_COLOR_FORMAT_RGB565:
		case IMX_VPU_API_COLOR_FORMAT_BGR565:
		case IMX_VPU_API_COLOR_FORMAT_RGB444:
		case IMX_VPU_API_COLOR_FORMAT_ARGB4444:
		case IMX_VPU_API_COLOR_FORMAT_ARGB1555:
			fb_metrics->y_stride = fb_metrics->aligned_frame_width * 2;
			fb_metrics->y_size = fb_metrics->y_stride * fb_metrics->aligned_frame_height;
			fb_metrics->uv_stride = 0;
			fb_metrics->uv_size = 0;
			break;

		case IMX_VPU_API_COLOR_FORMAT_RGBA8888:
		case IMX_VPU_API_COLOR_FORMAT_BGRA8888:
			fb_metrics->y_stride = fb_metrics->aligned_frame_width * 4;
			fb_metrics->y_size = fb_metrics->y_stride * fb_metrics->aligned_frame_height;
			fb_metrics->uv_stride = 0;
			fb_metrics->uv_size = 0;
			break;

		default:
			/* User specified an unknown color format. */
			IMX_VPU_API_ERROR("unknown/unsupported color format %s (%d)", imx_vpu_api_color_format_string(open_params->color_format), open_params->color_format);
			ret = IMX_VPU_API_ENC_RETURN_CODE_UNSUPPORTED_COLOR_FORMAT;
			goto cleanup;
	}

	/* Adjust the uv_stride and uv_size values in case we are using semi-planar chroma. */
	if (semi_planar)
	{
		fb_metrics->uv_stride *= 2;
		fb_metrics->uv_size *= 2;
	}

	fb_metrics->y_offset = 0;
	fb_metrics->u_offset = fb_metrics->y_size;
	fb_metrics->v_offset = fb_metrics->u_offset + fb_metrics->uv_size;

	/* Calculate the number of macroblocks in a row / a column / a frame,
	 * rounding up to also include "half-macroblocks". */
	(*encoder)->num_macroblocks_per_row = (fb_metrics->actual_frame_width + 15) / 16;
	(*encoder)->num_macroblocks_per_column = (fb_metrics->actual_frame_height + 15) / 16;
	(*encoder)->num_macroblocks_per_frame = (*encoder)->num_macroblocks_per_row * (*encoder)->num_macroblocks_per_column;
	IMX_VPU_API_DEBUG(
		"number of macroblocks per row / per column / per frame: %zu / %zu / %zu",
		(*encoder)->num_macroblocks_per_row,
		(*encoder)->num_macroblocks_per_column,
		(*encoder)->num_macroblocks_per_frame
	);

	(*encoder)->use_intra_refresh = (open_params->flags & IMX_VPU_API_ENC_OPEN_PARAMS_FLAG_USE_INTRA_REFRESH) || (open_params->min_intra_refresh_mb_count != 0);
	IMX_VPU_API_DEBUG("using intra refresh: %d", (*encoder)->use_intra_refresh);

	/* The Hantro H1 encoder does not use a framebuffer pool, so set this to 0. */
	(*encoder)->stream_info.min_num_required_framebuffers = 0;
	(*encoder)->stream_info.min_framebuffer_size = (semi_planar ? fb_metrics->u_offset : fb_metrics->v_offset) + fb_metrics->uv_size;
	(*encoder)->stream_info.frame_rate_numerator = open_params->frame_rate_numerator;
	(*encoder)->stream_info.frame_rate_denominator = open_params->frame_rate_denominator;
	/* Alignment determined by looking at the Hantro
	 * H264EncApi.c and vp8encapi.c sources. */
	(*encoder)->stream_info.framebuffer_alignment = 8;


	/* Now open the actual encoder. */

	switch (open_params->compression_format)
	{
		case IMX_VPU_API_COMPRESSION_FORMAT_VP8:
			(*encoder)->h1_encoder_functions = &h1_vp8_encoder_functions;
			break;

		case IMX_VPU_API_COMPRESSION_FORMAT_H264:
			(*encoder)->h1_encoder_functions = &h1_h264_encoder_functions;
			break;

		default:
			/* User specified an unknown compression format. */
			IMX_VPU_API_ERROR("unknown/unsupported compression format %s (%d)", imx_vpu_api_compression_format_string(open_params->compression_format), open_params->compression_format);
			ret = IMX_VPU_API_ENC_RETURN_CODE_UNSUPPORTED_COMPRESSION_FORMAT;
			goto cleanup;
	}

	ret = (*encoder)->h1_encoder_functions->open_encoder(*encoder, &((*encoder)->h1_encoder));
	if (ret != IMX_VPU_API_ENC_RETURN_CODE_OK)
		goto cleanup;


	/* Start the stream and produce bitstream headers. */

	{
		size_t output_size;

		(*encoder)->encoded_frame_is_sync_point = FALSE;

		ret = (*encoder)->h1_encoder_functions->start_stream((*encoder)->h1_encoder, &output_size);
		if (ret != IMX_VPU_API_ENC_RETURN_CODE_OK)
			goto cleanup;

		if (output_size > 0)
		{
			IMX_VPU_API_DEBUG("got header data with %zu byte", output_size);

			/* Copy the header data so we can insert it later if necessary. */
			(*encoder)->header_data = malloc(output_size);
			(*encoder)->header_data_size = output_size;

			/* Begin synced access since we have to copy the header
			 * data out of the stream buffer. */
			imx_dma_buffer_start_sync_session((*encoder)->stream_buffer);
			memcpy((*encoder)->header_data, (*encoder)->stream_buffer_virtual_address, output_size);
			imx_dma_buffer_stop_sync_session((*encoder)->stream_buffer);

			(*encoder)->must_prepend_header_data = TRUE;
		}
		else
		{
			IMX_VPU_API_DEBUG("got no header data");
			(*encoder)->header_data = NULL;
			(*encoder)->header_data_size = 0;
			(*encoder)->must_prepend_header_data = FALSE;
		}
	}


	/* Finish & cleanup. */
finish:
	if (ret == IMX_VPU_API_ENC_RETURN_CODE_OK)
		IMX_VPU_API_DEBUG("successfully opened encoder");

	return ret;

cleanup:
	if ((*encoder) != NULL)
	{
		imx_vpu_api_enc_close(*encoder);
		*encoder = NULL;
	}

	goto finish;
}


void imx_vpu_api_enc_close(ImxVpuApiEncoder *encoder)
{
	assert(encoder != NULL);

	if (encoder->h1_encoder != NULL)
		encoder->h1_encoder_functions->close_encoder(encoder->h1_encoder);

	if (encoder->stream_buffer_virtual_address != NULL)
		imx_dma_buffer_unmap(encoder->stream_buffer);

	free(encoder->header_data);
	free(encoder);
}


ImxVpuApiEncStreamInfo const * imx_vpu_api_enc_get_stream_info(ImxVpuApiEncoder *encoder)
{
	assert(encoder != NULL);
	return &(encoder->stream_info);
}


ImxVpuApiEncReturnCodes imx_vpu_api_enc_add_framebuffers_to_pool(ImxVpuApiEncoder *encoder, ImxDmaBuffer **fb_dma_buffers, size_t num_framebuffers)
{
	IMX_VPU_API_UNUSED_PARAM(encoder);
	IMX_VPU_API_UNUSED_PARAM(fb_dma_buffers);
	IMX_VPU_API_UNUSED_PARAM(num_framebuffers);
	IMX_VPU_API_ERROR("tried to add framebuffers, but this encoder does not use a framebuffer pool");
	return IMX_VPU_API_ENC_RETURN_CODE_INVALID_CALL;
}


void imx_vpu_api_enc_enable_drain_mode(ImxVpuApiEncoder *encoder)
{
	assert(encoder != NULL);
	encoder->drain_mode_enabled = TRUE;
}


int imx_vpu_api_enc_is_drain_mode_enabled(ImxVpuApiEncoder *encoder)
{
	assert(encoder != NULL);
	return encoder->drain_mode_enabled;
}


void imx_vpu_api_enc_flush(ImxVpuApiEncoder *encoder)
{
	assert(encoder != NULL);
	assert(encoder->h1_encoder != NULL);
	assert(encoder->h1_encoder_functions != NULL);

	encoder->h1_encoder_functions->flush(encoder->h1_encoder);

	/* Force the first frame after the flush to be an intra/IDR frame.
	 * This makes sure that decoders can show a video signal right away
	 * after the encoder got flushed. */
	encoder->force_IDR_frame = TRUE;
	encoder->staged_raw_frame_set = FALSE;
	encoder->encoded_frame_available = FALSE;
}


ImxVpuApiEncReturnCodes imx_vpu_api_enc_set_bitrate(ImxVpuApiEncoder *encoder, unsigned int bitrate)
{
	IMX_VPU_API_UNUSED_PARAM(encoder);
	IMX_VPU_API_UNUSED_PARAM(bitrate);

	/* XXX: Not supporting this, since CBR bitstreams with changing
	 * bit rates  can mess up decoders, which expect no such chnages.
	 * This function might be deprecated in a future version. */

	return IMX_VPU_API_ENC_RETURN_CODE_OK;
}


ImxVpuApiEncReturnCodes imx_vpu_api_enc_set_frame_rate(ImxVpuApiEncoder *encoder, unsigned int frame_rate_numerator, unsigned int frame_rate_denominator)
{
	// TODO

	return IMX_VPU_API_ENC_RETURN_CODE_OK;
}


ImxVpuApiEncReturnCodes imx_vpu_api_enc_push_raw_frame(ImxVpuApiEncoder *encoder, ImxVpuApiRawFrame const *raw_frame)
{
	assert(encoder != NULL);
	assert(raw_frame != NULL);

	if (encoder->staged_raw_frame_set)
	{
		IMX_VPU_API_ERROR("tried to push a raw frame before a previous one was encoded");
		return IMX_VPU_API_ENC_RETURN_CODE_INVALID_CALL;
	}

	IMX_VPU_API_LOG("staged raw frame");

	/* Stage the raw frame. We cannot use it here right away, since the CODA
	 * encoder has no separate function to push raw frames into it. Instead,
	 * just keep track of it here, and actually use it in imx_vpu_api_enc_encode(). */
	encoder->staged_raw_frame = *raw_frame;
	encoder->staged_raw_frame_physical_address = imx_dma_buffer_get_physical_address(encoder->staged_raw_frame.fb_dma_buffer);

	encoder->staged_raw_frame_set = TRUE;

	return IMX_VPU_API_ENC_RETURN_CODE_OK;
}


ImxVpuApiEncReturnCodes imx_vpu_api_enc_encode(ImxVpuApiEncoder *encoder, size_t *encoded_frame_size, ImxVpuApiEncOutputCodes *output_code)
{
	ImxVpuApiEncReturnCodes ret = IMX_VPU_API_ENC_RETURN_CODE_OK;
	ImxVpuApiFrameType frame_type;

	assert(encoder != NULL);
	assert(encoder->h1_encoder != NULL);
	assert(encoder->h1_encoder_functions != NULL);
	assert(encoded_frame_size != NULL);
	assert(output_code != NULL);

	if (encoder->encoded_frame_available)
	{
		IMX_VPU_API_ERROR("cannot encode new frame before the old one was retrieved");
		ret = IMX_VPU_API_ENC_RETURN_CODE_INVALID_CALL;
		goto finish;
	}

	if (!(encoder->staged_raw_frame_set))
	{
		IMX_VPU_API_TRACE("no data left to encode");
		*output_code = IMX_VPU_API_ENC_OUTPUT_CODE_MORE_INPUT_DATA_NEEDED;
		ret = IMX_VPU_API_ENC_RETURN_CODE_OK;
		goto finish;
	}

	*output_code = IMX_VPU_API_ENC_OUTPUT_CODE_NO_OUTPUT_YET_AVAILABLE;


	IMX_VPU_API_LOG("encoding raw_frame with physical address %" IMX_PHYSICAL_ADDRESS_FORMAT, encoder->staged_raw_frame_physical_address);


	*encoded_frame_size = 0;
	encoder->num_bytes_in_stream_buffer = 0;
	frame_type = encoder->force_IDR_frame ? IMX_VPU_API_FRAME_TYPE_IDR : encoder->staged_raw_frame.frame_types[0];

	ret = encoder->h1_encoder_functions->encode_frame(encoder->h1_encoder, frame_type, encoded_frame_size, &(encoder->encoded_frame_type), output_code);
	if (ret != IMX_VPU_API_ENC_RETURN_CODE_OK)
		goto finish;

	if (encoder->encoded_frame_type == IMX_VPU_API_FRAME_TYPE_SKIP)
	{
		*encoded_frame_size = 0;
		*output_code = IMX_VPU_API_ENC_OUTPUT_CODE_FRAME_SKIPPED;

		/* There is no frame available, but the caller might still need
		 * the skipped frame's metadata, so store that here. */
		encoder->encoded_frame_context = encoder->staged_raw_frame.context;
		encoder->encoded_frame_pts = encoder->staged_raw_frame.pts;
		encoder->encoded_frame_dts = encoder->staged_raw_frame.dts;
		encoder->encoded_frame_data_size = 0;
		encoder->encoded_frame_available = FALSE;

		encoder->num_bytes_in_stream_buffer = 0;

		IMX_VPU_API_LOG("encoder skipped this frame");
	}
	else
	{
		*output_code = IMX_VPU_API_ENC_OUTPUT_CODE_ENCODED_FRAME_AVAILABLE;

		/* Copy over metadata from the raw frame to the encoded frame. Since the
		 * encoder does not perform any kind of delay or reordering, this is
		 * appropriate, because in that case, one input frame always immediately
		 * leads to one output frame. */
		encoder->encoded_frame_context = encoder->staged_raw_frame.context;
		encoder->encoded_frame_pts = encoder->staged_raw_frame.pts;
		encoder->encoded_frame_dts = encoder->staged_raw_frame.dts;
		encoder->encoded_frame_data_size = *encoded_frame_size;
		encoder->encoded_frame_available = TRUE;

		encoder->force_IDR_frame = FALSE;

		IMX_VPU_API_LOG("encoded frame (including header if any is present) has a size of %zu byte and is of type %s", *encoded_frame_size, imx_vpu_api_frame_type_string(encoder->encoded_frame_type));
	}


finish:
	encoder->staged_raw_frame_set = FALSE;

	return ret;
}


ImxVpuApiEncReturnCodes imx_vpu_api_enc_get_encoded_frame(ImxVpuApiEncoder *encoder, ImxVpuApiEncodedFrame *encoded_frame)
{
	return imx_vpu_api_enc_get_encoded_frame_ext(encoder, encoded_frame, NULL);
}


ImxVpuApiEncReturnCodes imx_vpu_api_enc_get_encoded_frame_ext(ImxVpuApiEncoder *encoder, ImxVpuApiEncodedFrame *encoded_frame, int *is_sync_point)
{
	assert(encoder != NULL);
	assert(encoded_frame != NULL);
	assert(encoded_frame->data != NULL);

	if (!(encoder->encoded_frame_available))
	{
		IMX_VPU_API_ERROR("cannot retrieve encoded frame since there is none");
		return IMX_VPU_API_ENC_RETURN_CODE_INVALID_CALL;
	}

	if (encoder->encoded_frame_type != IMX_VPU_API_FRAME_TYPE_SKIP)
		encoder->h1_encoder_functions->get_encoded_data(encoder->h1_encoder, encoded_frame);

	/* Copy encoded frame metadata. */

	encoded_frame->data_size = encoder->encoded_frame_data_size;
	encoded_frame->has_header = (encoder->encoded_frame_type == IMX_VPU_API_FRAME_TYPE_IDR);
	encoded_frame->frame_type = encoder->encoded_frame_type;
	encoded_frame->context = encoder->encoded_frame_context;
	encoded_frame->pts = encoder->encoded_frame_pts;
	encoded_frame->dts = encoder->encoded_frame_dts;

	if (is_sync_point != NULL)
		*is_sync_point = encoder->encoded_frame_is_sync_point;

	/* Reset some flags for the next imx_vpu_api_enc_encode() call,
	 * since we are done with this frame. */
	encoder->encoded_frame_available = FALSE;
	encoder->num_bytes_in_stream_buffer = 0;

	return IMX_VPU_API_ENC_RETURN_CODE_OK;
}


ImxVpuApiEncReturnCodes imx_vpu_api_enc_get_skipped_frame_info(ImxVpuApiEncoder *encoder, void **context, uint64_t *pts, uint64_t *dts)
{
	assert(encoder != NULL);

	if (encoder->encoded_frame_type != IMX_VPU_API_FRAME_TYPE_SKIP)
	{
		IMX_VPU_API_ERROR("frame was not skipped");
		return IMX_VPU_API_ENC_RETURN_CODE_INVALID_CALL;
	}

	if (context != NULL)
		*context = encoder->encoded_frame_context;
	if (pts != NULL)
		*pts = encoder->encoded_frame_pts;
	if (dts != NULL)
		*dts = encoder->encoded_frame_dts;

	return IMX_VPU_API_ENC_RETURN_CODE_OK;
}



/**************************************************************/
/******* HANTRO H1 VP8 ENCODER STRUCTURES AND FUNCTIONS *******/
/**************************************************************/


static ImxVpuApiEncReturnCodes h1_vp8_open_encoder(ImxVpuApiEncoder *base, void **h1_encoder);
static void h1_vp8_close_encoder(void *h1_encoder);

static ImxVpuApiEncReturnCodes h1_vp8_start_stream(void *h1_encoder, size_t *output_size);

static ImxVpuApiEncReturnCodes h1_vp8_encode_frame(void *h1_encoder, ImxVpuApiFrameType frame_type, size_t *encoded_frame_size, ImxVpuApiFrameType *encoded_frame_type, ImxVpuApiEncOutputCodes *output_code);
static void h1_vp8_get_encoded_data(void *h1_encoder, ImxVpuApiEncodedFrame *encoded_frame);

static void h1_vp8_flush(void *h1_encoder);

static char const * h1_vp8_encoder_ret_to_string(VP8EncRet enc_ret);
static char const * h1_vp8_encoder_interpolation_filter_to_string(uint32_t filter);
static char const * h1_vp8_encoder_deblocking_loop_filter_type_to_string(uint32_t filter_type);
static char const * h1_vp8_encoder_quality_metric_to_string(uint32_t metric);

static HantroH1EncoderFunctions const h1_vp8_encoder_functions = {
	.open_encoder = h1_vp8_open_encoder,
	.close_encoder = h1_vp8_close_encoder,

	.start_stream = h1_vp8_start_stream,

	.encode_frame = h1_vp8_encode_frame,
	.get_encoded_data = h1_vp8_get_encoded_data,

	.flush = h1_vp8_flush,
};

/* NOTE ABOUT INTRA REFRESH IN VP8 ENCODER:
 *
 * Intra refresh is not an official part of VP8, but can be emulated by forcing
 * some macroblocks in a frame to be intra macroblocks. However, there is no known
 * way to add metadata to the stream to inform decoders about intra refresh, so
 * this unofficial support is not compatible out of the box with VP8 decoders.
 * In particular, a VP8 live stream with this unofficial intra refresh method
 * in use will not be decoded with such decoders if they join the live stream
 * mid-streaming (that is, the decoders then missed the initial I frame). For
 * this reason, intra refresh support for VP8 encoding is considered experimental. */

typedef struct
{
	ImxVpuApiEncoder *base;
	VP8EncInst handle;
	VP8EncIn input;
	VP8EncOut output;
	BOOL is_first_frame;
	unsigned int gop_frame_counter;

	BOOL periodic_ir_finished;
	unsigned int periodic_ir_frame_counter;
	unsigned int periodic_ir_total_amount;
}
H1VP8Encoder;

static ImxVpuApiEncReturnCodes h1_vp8_open_encoder(ImxVpuApiEncoder *base, void **h1_encoder)
{
	ImxVpuApiEncReturnCodes ret = IMX_VPU_API_ENC_RETURN_CODE_OK;
	ImxVpuApiEncOpenParams *open_params;
	ImxVpuApiFramebufferMetrics *fb_metrics;
	H1VP8Encoder *encoder = NULL;
	VP8EncConfig config;
	VP8EncApiVersion api_version;
	VP8EncBuild encoder_build;
	VP8EncCodingCtrl coding_control;
	VP8EncRateCtrl rate_control;
	VP8EncPreProcessingCfg preprocessor_config;
	VP8EncRet enc_ret;

	assert(base != NULL);
	assert(h1_encoder != NULL);


	/* Initial preparations */

	encoder = malloc(sizeof(H1VP8Encoder));
	assert(encoder != NULL);

	open_params = &(base->open_params);
	fb_metrics = &(base->stream_info.frame_encoding_framebuffer_metrics);

	encoder->base = base;

	if (base->use_intra_refresh)
	{
		/* At the start of each GOP (except the first one), frames are produced
		 *  which are partially made of intra macroblocks, as a replacement for
		 * intra frames. In each one of these frames, at least 3 macroblock rows
		 * shall be made of intra macroblocks. Having 3 macroblock rows per
		 * frame is a compromise between intra refresh bitrate stability and
		 * intra coding efficiency; the fewer rows, the lesser the impact on
		 * the bitrate, but also, the less efficient the intra coding becomes,
		 * because the intra macroblocks have fewer other intra macroblocks to
		 * refer to. Calculate how many periodic IR frames would need to be
		 * produced to refresh all macroblocks if 3 rows per frame get refreshed.
		 *
		 * The result of the integer division is intentionally truncated. That
		 * way, the number of macroblock rows per frame is _at least_ 3. See
		 * the periodic IR calculations in h1_vp8_encode_frame() for details.
		 *
		 * It is possible that the GOP size is so small that with the computed
		 * amount of periodic IR frames a full refresh would not be possible.
		 * (The next GOP would start before the current GOP refreshed the contents.)
		 * In such a case, use the GOP size as the periodic IR frame mount.
		 * This will lead to more intra macroblock rows per frame, which can
		 * negatively impact bitrate stability, but with a small GOP size, there
		 * isn't any other choice. */

		encoder->periodic_ir_total_amount = base->num_macroblocks_per_column / 3;

		if (encoder->periodic_ir_total_amount > open_params->gop_size)
			encoder->periodic_ir_total_amount = open_params->gop_size;

		IMX_VPU_API_DEBUG("total amount of period intra refresh frames in VP8 stream: %u", encoder->periodic_ir_total_amount);
	}
	else
		IMX_VPU_API_DEBUG("periodic intra refresh is not used; not enabling it in VP8 stream");

	base->stream_info.format_specific_open_params.vp8_open_params = open_params->format_specific_open_params.vp8_open_params;

	api_version = VP8EncGetApiVersion();
	encoder_build = VP8EncGetBuild();
	IMX_VPU_API_INFO(
		"Hantro H1 VP8 encoder API version %d.%d hardware ID %c%c 0x%08x software build %d.%d.%d",
		(int)(api_version.major), (int)(api_version.minor),
		(char)((encoder_build.hwBuild >> 24) & 0xFF), (char)((encoder_build.hwBuild>>16) & 0xFF),
		(uint32_t)(encoder_build.hwBuild),
		(int)(encoder_build.swBuild / 1000000), (int)((encoder_build.swBuild / 1000) % 1000), (int)(encoder_build.swBuild % 1000)
	);


	/* Basic encoder configuration and initialization */

	memset(&config, 0, sizeof(config));
	config.refFrameAmount = 1;
	config.width = fb_metrics->aligned_frame_width;
	config.height = fb_metrics->aligned_frame_height;
	config.frameRateNum = open_params->frame_rate_numerator;
	config.frameRateDenom = open_params->frame_rate_denominator;
	config.scaledWidth = 0;
	config.scaledHeight = 0;

	enc_ret = VP8EncInit(&config, &(encoder->handle));
	if (enc_ret != VP8ENC_OK)
	{
		IMX_VPU_API_ERROR("could not initialize VP8 encoder: %s", h1_vp8_encoder_ret_to_string(enc_ret));
		if (enc_ret == VP8ENC_INVALID_ARGUMENT)
			ret = IMX_VPU_API_ENC_RETURN_CODE_INVALID_PARAMS;
		goto error;
	}


	/* Coding control setup */

	/* Get the defaults */
	memset(&coding_control, 0, sizeof(coding_control));
	enc_ret = VP8EncGetCodingCtrl(encoder->handle, &coding_control);
	if (enc_ret != VP8ENC_OK)
	{
		IMX_VPU_API_ERROR("could not get default VP8 encoder coding control setup: %s", h1_vp8_encoder_ret_to_string(enc_ret));
		goto error;
	}

	/* Let the filter be automatically adjusted based on quantization. */
	coding_control.filterLevel = VP8ENC_FILTER_LEVEL_AUTO;
	coding_control.filterSharpness = VP8ENC_FILTER_SHARPNESS_AUTO;
	coding_control.errorResilient = open_params->format_specific_open_params.vp8_open_params.error_resilient_mode ? 1 : 0;
	/* Adaptive quarter pixel motion estimation */
	coding_control.quarterPixelMv = 1;

	/* Configure filters according to RFC 6386 section 9.1 ("Uncompressed Data Chunk"). */
	switch (open_params->format_specific_open_params.vp8_open_params.profile)
	{
		case IMX_VPU_API_VP8_PROFILE_0:
			coding_control.interpolationFilter = 0;
			coding_control.filterType = 0;
			break;
		case IMX_VPU_API_VP8_PROFILE_1:
			coding_control.interpolationFilter = 1;
			coding_control.filterType = 1;
			break;
		case IMX_VPU_API_VP8_PROFILE_2:
			coding_control.interpolationFilter = 1;
			coding_control.filterType = 0;
			coding_control.filterLevel = 0;
			break;
		case IMX_VPU_API_VP8_PROFILE_3:
			coding_control.interpolationFilter = 2;
			coding_control.filterType = 0;
			coding_control.filterLevel = 0;
			break;
		default:
			IMX_VPU_API_ERROR("unknown/unsupported VP8 profile");
			ret = IMX_VPU_API_ENC_RETURN_CODE_UNSUPPORTED_COMPRESSION_FORMAT_PARAMS;
			goto error;
	}

	switch (open_params->format_specific_open_params.vp8_open_params.partition_count)
	{
		case IMX_VPU_API_ENC_VP8_PARTITION_COUNT_1: coding_control.dctPartitions = 0; break;
		case IMX_VPU_API_ENC_VP8_PARTITION_COUNT_2: coding_control.dctPartitions = 1; break;
		case IMX_VPU_API_ENC_VP8_PARTITION_COUNT_4: coding_control.dctPartitions = 2; break;
		case IMX_VPU_API_ENC_VP8_PARTITION_COUNT_8: coding_control.dctPartitions = 3; break;
		default:
			IMX_VPU_API_ERROR("invalid VP8 partition count");
			ret = IMX_VPU_API_ENC_RETURN_CODE_INVALID_PARAMS;
			goto error;
	}

	IMX_VPU_API_DEBUG("VP8 coding control setup:");
	IMX_VPU_API_DEBUG("  interpolation filter: %s (%" PRIu32 ")", h1_vp8_encoder_interpolation_filter_to_string(coding_control.interpolationFilter), (uint32_t)(coding_control.interpolationFilter));
	IMX_VPU_API_DEBUG("  deblocking loop filter type: %s (%" PRIu32 ")", h1_vp8_encoder_deblocking_loop_filter_type_to_string(coding_control.filterType), (uint32_t)(coding_control.filterType));

	if (coding_control.filterLevel == VP8ENC_FILTER_LEVEL_AUTO)
		IMX_VPU_API_DEBUG("  deblocking loop filter level: (automatically calculated based on quantization)");
	else
		IMX_VPU_API_DEBUG("  deblocking loop filter level: %" PRIu32, (uint32_t)(coding_control.filterLevel));

	if (coding_control.filterSharpness == VP8ENC_FILTER_SHARPNESS_AUTO)
		IMX_VPU_API_DEBUG("  deblocking loop filter sharpness: (automatically calculated)");
	else
		IMX_VPU_API_DEBUG("  deblocking loop filter sharpness: %" PRIu32, (uint32_t)(coding_control.filterSharpness));

	IMX_VPU_API_DEBUG("  amount of DCT coefficient partitions: %d", imx_vpu_api_vp8_partition_count_number(open_params->format_specific_open_params.vp8_open_params.partition_count));
	IMX_VPU_API_DEBUG("  error resilient mode: %s (%" PRIu32 ")", imx_vpu_api_h1_encoder_2state_mode_to_string(coding_control.errorResilient), (uint32_t)(coding_control.errorResilient));
	IMX_VPU_API_DEBUG("  split motion vector mode: %s (%" PRIu32 ")", imx_vpu_api_h1_encoder_3state_mode_to_string(coding_control.splitMv), (uint32_t)(coding_control.splitMv));
	IMX_VPU_API_DEBUG("  quarter pixel motion estimation mode: %s (%" PRIu32 ")", imx_vpu_api_h1_encoder_3state_mode_to_string(coding_control.quarterPixelMv), (uint32_t)(coding_control.quarterPixelMv));
	IMX_VPU_API_DEBUG("  forced intra macroblock area: enabled: %" PRIu32 " left/top/right/bottom: %" PRIu32 "/%" PRIu32 "/%" PRIu32 "/%" PRIu32,
		(uint32_t)(coding_control.intraArea.enable),
		(uint32_t)(coding_control.intraArea.left),
		(uint32_t)(coding_control.intraArea.top),
		(uint32_t)(coding_control.intraArea.right),
		(uint32_t)(coding_control.intraArea.bottom)
	);
	IMX_VPU_API_DEBUG("  forced ROI 1 macroblock area: enabled: %" PRIu32 " left/top/right/bottom: %" PRIu32 "/%" PRIu32 "/%" PRIu32 "/%" PRIu32,
		(uint32_t)(coding_control.roi1Area.enable),
		(uint32_t)(coding_control.roi1Area.left),
		(uint32_t)(coding_control.roi1Area.top),
		(uint32_t)(coding_control.roi1Area.right),
		(uint32_t)(coding_control.roi1Area.bottom)
	);
	IMX_VPU_API_DEBUG("  forced ROI 2 macroblock area: enabled: %" PRIu32 " left/top/right/bottom: %" PRIu32 "/%" PRIu32 "/%" PRIu32 "/%" PRIu32,
		(uint32_t)(coding_control.roi2Area.enable),
		(uint32_t)(coding_control.roi2Area.left),
		(uint32_t)(coding_control.roi2Area.top),
		(uint32_t)(coding_control.roi2Area.right),
		(uint32_t)(coding_control.roi2Area.bottom)
	);
	IMX_VPU_API_DEBUG("  ROI 1 delta QP: %" PRId32, (int32_t)(coding_control.roi1DeltaQp));
	IMX_VPU_API_DEBUG("  ROI 2 delta QP: %" PRId32, (int32_t)(coding_control.roi2DeltaQp));
	IMX_VPU_API_DEBUG("  deadzone optimization: %s (%" PRIu32 ")", imx_vpu_api_h1_encoder_2state_mode_to_string(coding_control.deadzone), (uint32_t)(coding_control.deadzone));
	IMX_VPU_API_DEBUG("  max num passes: %" PRIu32, (uint32_t)(coding_control.maxNumPasses));
	IMX_VPU_API_DEBUG("  quality metric: %s", h1_vp8_encoder_quality_metric_to_string(coding_control.qualityMetric));
	IMX_VPU_API_DEBUG("  luma DC QP delta: %" PRId32, (int32_t)(coding_control.qpDelta[0]));
	IMX_VPU_API_DEBUG("  2nd order luma DC QP delta: %" PRId32, (int32_t)(coding_control.qpDelta[1]));
	IMX_VPU_API_DEBUG("  2nd order luma AC QP delta: %" PRId32, (int32_t)(coding_control.qpDelta[2]));
	IMX_VPU_API_DEBUG("  chroma DC QP delta: %" PRId32, (int32_t)(coding_control.qpDelta[3]));
	IMX_VPU_API_DEBUG("  chroma AC QP delta: %" PRId32, (int32_t)(coding_control.qpDelta[4]));
	IMX_VPU_API_DEBUG("  adaptive ROI QP delta: %" PRId32, (int32_t)(coding_control.adaptiveRoi));
	IMX_VPU_API_DEBUG("  adaptive ROI temperature sensitivity (in Kelvin): %" PRId32, (int32_t)(coding_control.adaptiveRoiColor));

	enc_ret = VP8EncSetCodingCtrl(encoder->handle, &coding_control);
	if (enc_ret != VP8ENC_OK)
	{
		IMX_VPU_API_ERROR("could not set VP8 encoder coding control setup: %s", h1_vp8_encoder_ret_to_string(enc_ret));
		if (enc_ret == VP8ENC_INVALID_ARGUMENT)
			ret = IMX_VPU_API_ENC_RETURN_CODE_INVALID_PARAMS;
		goto error;
	}


	/* Rate control setup */

	/* Get the defaults */
	memset(&rate_control, 0, sizeof(rate_control));
	enc_ret = VP8EncGetRateCtrl(encoder->handle, &rate_control);
	if (enc_ret != VP8ENC_OK)
	{
		IMX_VPU_API_ERROR("could not get default VP8 encoder rate control setup: %s", h1_vp8_encoder_ret_to_string(enc_ret));
		goto error;
	}

	rate_control.qpMin = 0;
	rate_control.qpMax = 127;
	rate_control.bitPerSecond = open_params->bitrate * 1000;
	/* Temporal layers are (currently) not supported. */
	rate_control.layerBitPerSecond[0] = 0;
	rate_control.layerBitPerSecond[1] = 0;
	rate_control.layerBitPerSecond[2] = 0;
	rate_control.layerBitPerSecond[3] = 0;

	if (open_params->bitrate != 0)
	{
		int fixed_intra_qp = open_params->fixed_intra_quantization;

		rate_control.pictureRc = 1;
		rate_control.pictureSkip = (open_params->flags & IMX_VPU_API_ENC_OPEN_PARAMS_FLAG_ALLOW_FRAMESKIPPING) ? 1 : 0;
		rate_control.qpHdr = -1; /* -1 = Let rate control calculate initial QP */
		rate_control.fixedIntraQp = (fixed_intra_qp > 0) ? fixed_intra_qp : 0; /* 0 = rate control calculates intra QP */
	}
	else
	{
		rate_control.pictureRc = 0;
		rate_control.pictureSkip = 0;
		rate_control.qpHdr = open_params->quantization;
		rate_control.fixedIntraQp = open_params->quantization;
	}

	IMX_VPU_API_DEBUG("VP8 rate control setup:");
	IMX_VPU_API_DEBUG("  picture rate control: %s (%" PRIu32 ")", imx_vpu_api_h1_encoder_2state_mode_to_string(rate_control.pictureRc), (uint32_t)(rate_control.pictureRc));
	IMX_VPU_API_DEBUG("  allow rate control to skip pictures: %" PRIu32, (uint32_t)(rate_control.pictureSkip));
	IMX_VPU_API_DEBUG("  bits per second: %" PRIu32, (uint32_t)(rate_control.bitPerSecond));
	IMX_VPU_API_DEBUG("  bitrate window: %" PRIu32, (uint32_t)(rate_control.bitrateWindow));
	IMX_VPU_API_DEBUG("  intra QP delta: %" PRId32, (int32_t)(rate_control.intraQpDelta));

	if (rate_control.fixedIntraQp == 0)
		IMX_VPU_API_DEBUG("  fixed intra QP: (automatically calculated based by rate control)");
	else
		IMX_VPU_API_DEBUG("  fixed intra QP: %" PRIu32, (uint32_t)(rate_control.fixedIntraQp));

	IMX_VPU_API_DEBUG("  intra picture rate: %" PRIu32, (uint32_t)(rate_control.intraPictureRate));
	IMX_VPU_API_DEBUG("  golden picture rate: %" PRIu32, (uint32_t)(rate_control.goldenPictureRate));
	IMX_VPU_API_DEBUG("  altref picture rate: %" PRIu32, (uint32_t)(rate_control.altrefPictureRate));
	IMX_VPU_API_DEBUG("  golden picture quality boost: %" PRIu32, (uint32_t)(rate_control.goldenPictureBoost));
	IMX_VPU_API_DEBUG("  adaptive golden picture quality boost: %" PRIu32, (uint32_t)(rate_control.adaptiveGoldenBoost));
	IMX_VPU_API_DEBUG("  adaptive golden picture update: %s (%" PRIu32 ")", imx_vpu_api_h1_encoder_2state_mode_to_string(rate_control.adaptiveGoldenUpdate), (uint32_t)(rate_control.adaptiveGoldenUpdate));

	enc_ret = VP8EncSetRateCtrl(encoder->handle, &rate_control);
	if (enc_ret != VP8ENC_OK)
	{
		IMX_VPU_API_ERROR("could not set VP8 encoder rate control setup: %s", h1_vp8_encoder_ret_to_string(enc_ret));
		if (enc_ret == VP8ENC_INVALID_ARGUMENT)
			ret = IMX_VPU_API_ENC_RETURN_CODE_INVALID_PARAMS;
		goto error;
	}


	/* Preprocessor setup */

	/* Get the defaults */
	memset(&preprocessor_config, 0, sizeof(preprocessor_config));
	enc_ret = VP8EncGetPreProcessing(encoder->handle, &preprocessor_config);
	if (enc_ret != VP8ENC_OK)
	{
		IMX_VPU_API_ERROR("could not get default VP8 preprocessor config: %s", h1_vp8_encoder_ret_to_string(enc_ret));
		goto error;
	}

	preprocessor_config.origWidth = fb_metrics->aligned_frame_width;
	preprocessor_config.origHeight = fb_metrics->aligned_frame_height;
	/* Preprocessing is (currently) not supported by the imxvpuapi encoder API */
	preprocessor_config.xOffset = 0;
	preprocessor_config.yOffset = 0;
	preprocessor_config.rotation = VP8ENC_ROTATE_0;
	preprocessor_config.videoStabilization = 0;
	/* Currently, setting this through the API is not supported. Use BT.709,
	 * since that's what is used in HD video, and that is what nowadays
	 * is primarily used (BT.601 was made for old analog TV). */
	preprocessor_config.colorConversion.type = VP8ENC_RGBTOYUV_BT709;
	preprocessor_config.scaledOutput = 0;

	switch (open_params->color_format)
	{
		case IMX_VPU_API_COLOR_FORMAT_FULLY_PLANAR_YUV420_8BIT:
			preprocessor_config.inputType = VP8ENC_YUV420_PLANAR;
			break;
		case IMX_VPU_API_COLOR_FORMAT_SEMI_PLANAR_YUV420_8BIT:
			preprocessor_config.inputType = VP8ENC_YUV420_SEMIPLANAR;
			break;
		case IMX_VPU_API_COLOR_FORMAT_PACKED_YUV422_UYVY_8BIT:
			preprocessor_config.inputType = VP8ENC_YUV422_INTERLEAVED_UYVY;
			break;
		case IMX_VPU_API_COLOR_FORMAT_PACKED_YUV422_YUYV_8BIT:
			preprocessor_config.inputType = VP8ENC_YUV422_INTERLEAVED_YUYV;
			break;
		case IMX_VPU_API_COLOR_FORMAT_RGB565:
			preprocessor_config.inputType = VP8ENC_RGB565;
			break;
		case IMX_VPU_API_COLOR_FORMAT_BGR565:
			preprocessor_config.inputType = VP8ENC_BGR565;
			break;
		case IMX_VPU_API_COLOR_FORMAT_ARGB1555:
			preprocessor_config.inputType = VP8ENC_RGB555;
			break;
		case IMX_VPU_API_COLOR_FORMAT_RGB444:
		case IMX_VPU_API_COLOR_FORMAT_ARGB4444:
			preprocessor_config.inputType = VP8ENC_RGB444;
			break;
		case IMX_VPU_API_COLOR_FORMAT_RGBA8888:
			preprocessor_config.inputType = VP8ENC_BGR888;
			break;
		case IMX_VPU_API_COLOR_FORMAT_BGRA8888:
			preprocessor_config.inputType = VP8ENC_RGB888;
			break;
		default:
			/* Invalid/unsupported color formats should already have been
			 * taken care of by the code in imx_vpu_api_enc_open(). */
			assert(FALSE);
	}

	enc_ret = VP8EncSetPreProcessing(encoder->handle, &preprocessor_config);
	if (enc_ret != VP8ENC_OK)
	{
		IMX_VPU_API_ERROR("could not set VP8 preprocessor config: %s", h1_vp8_encoder_ret_to_string(enc_ret));
		if (enc_ret == VP8ENC_INVALID_ARGUMENT)
			ret = IMX_VPU_API_ENC_RETURN_CODE_INVALID_PARAMS;
		goto error;
	}


finish:
	*h1_encoder = encoder;
	return ret;

error:
	h1_vp8_close_encoder(encoder);
	encoder = NULL;
	if (ret == IMX_VPU_API_ENC_RETURN_CODE_OK)
		ret = IMX_VPU_API_ENC_RETURN_CODE_ERROR;
	goto finish;
}

static void h1_vp8_close_encoder(void *h1_encoder)
{
	H1VP8Encoder *encoder = (H1VP8Encoder *)h1_encoder;

	if (encoder == NULL)
		return;

	if (encoder->handle != NULL)
		VP8EncRelease(encoder->handle);

	free(encoder);
}

static ImxVpuApiEncReturnCodes h1_vp8_start_stream(void *h1_encoder, size_t *output_size)
{
	H1VP8Encoder *encoder = (H1VP8Encoder *)h1_encoder;

	*output_size = 0;
	encoder->is_first_frame = TRUE;
	encoder->gop_frame_counter = 0;
	encoder->periodic_ir_finished = FALSE;
	encoder->periodic_ir_frame_counter = 0;

	return IMX_VPU_API_ENC_RETURN_CODE_OK;
}

static ImxVpuApiEncReturnCodes h1_vp8_encode_frame(void *h1_encoder, ImxVpuApiFrameType frame_type, size_t *encoded_frame_size, ImxVpuApiFrameType *encoded_frame_type, ImxVpuApiEncOutputCodes *output_code)
{
	int i;
	VP8EncRet enc_ret;
	H1VP8Encoder *encoder = (H1VP8Encoder *)h1_encoder;
	ImxVpuApiEncoder *base = encoder->base;
	ImxVpuApiFramebufferMetrics *fb_metrics = &(encoder->base->stream_info.frame_encoding_framebuffer_metrics);

	encoder->input.busLuma = (ptr_t)(base->staged_raw_frame_physical_address + fb_metrics->y_offset);
	encoder->input.busChromaU = (ptr_t)(base->staged_raw_frame_physical_address + fb_metrics->u_offset);
	encoder->input.busChromaV = (ptr_t)(base->staged_raw_frame_physical_address + fb_metrics->v_offset);
	encoder->input.timeIncrement = encoder->is_first_frame ? 0 : base->open_params.frame_rate_denominator;
	encoder->input.pOutBuf = (u32 *)(base->stream_buffer_virtual_address);
	encoder->input.busOutBuf = base->stream_buffer_physical_address;
	encoder->input.outBufSize = base->stream_buffer_size;
	encoder->input.busLumaStab = 0;
	encoder->input.layerId = 0;
	/* Use and refresh the previous frame, but do not use golden
	 * or altref frames (these are currently not supported). */
	encoder->input.ipf = VP8ENC_REFERENCE_AND_REFRESH;
	encoder->input.grf = VP8ENC_NO_REFERENCE_NO_REFRESH;
	encoder->input.arf = VP8ENC_NO_REFERENCE_NO_REFRESH;

	/* Enforce an I frame at the start of GOPs, and reset the counter,
	 * since this is a new GOP. If intra refresh is active, the behavior
	 * is different however: An I frame is only produced in the very first
	 * GOP (to have valid contents from the start). Afterwards, no more
	 * I frames are produced; instead, in each GOP, the first
	 * periodic_ir_total_amount frames contain intra macroblock rows. */
	if ((encoder->gop_frame_counter % base->open_params.gop_size) == 0)
	{
		if (base->use_intra_refresh && (encoder->gop_frame_counter != 0))
		{
			/* Reset periodic IR states at the start of each GOP. */
			encoder->periodic_ir_finished = FALSE;
			encoder->periodic_ir_frame_counter = 0;
		}
		else
			frame_type = IMX_VPU_API_FRAME_TYPE_I;

		encoder->gop_frame_counter = 0;
		encoder->base->encoded_frame_is_sync_point = TRUE;
	}
	else
		encoder->base->encoded_frame_is_sync_point = FALSE;

	if (base->use_intra_refresh && !(encoder->periodic_ir_finished))
	{
		if (!encoder->is_first_frame)
		{
			VP8EncCodingCtrl coding_control;
			unsigned int top, bottom;

			enc_ret = VP8EncGetCodingCtrl(encoder->handle, &coding_control);
			if (enc_ret != VP8ENC_OK)
			{
				IMX_VPU_API_ERROR("could not get default VP8 encoder coding control setup: %s", h1_vp8_encoder_ret_to_string(enc_ret));
				return IMX_VPU_API_ENC_RETURN_CODE_ERROR;
			}

			/* Compute the top and bottom coordinates of the forced intra macroblock area.
			 * This area will move vertically from top to bottom during the first
			 * periodic_ir_total_amount frames in the GOP. We use linear interpolation
			 * here to produce scaled row coordinates. periodic_ir_frame_counter is 0 at
			 * first, and is incremented after each encoded frame. Its last valid value
			 * will be (encoder->periodic_ir_total_amount - 1). The ratio betwen this and
			 * encoder->periodic_ir_total_amount is used for scaling the valuer of
			 * (base->num_macroblocks_per_column - 1). Since the ratio is never above 1.0,
			 * the coordinates can never exceed the boundaries of the frame.
			 *
			 * Once the last periodic IR frame in the GOP is reached, periodic_ir_finished
			 * is set to TRUE to prevent any further periodic IR processing from taking
			 * place within this GOP. (It will be done again when the next GOP starts.)
			 *
			 * The bottom coordinate adds 1 to the periodic_ir_frame_counter to factor in
			 * that at least 3 macroblock rows shall be intra coded. Also,k If this is not
			 * the first periodic IR frame in the GOP, top is incremented to account for
			 * the fact that both the bottom and the top coordinate in the intraArea are
			 * inclusive, that is, _inside_ the intraArea.
			 *
			 * (All divisions are integer division, and truncate non-integer results.)
			 *
			 * Example: 48 macroblocks per column. periodic_ir_total_amount is 16.
			 * In GOP frame #0, top is: 0 * (48 - 1) / 16 = 0.
			 * bottom is: (0 + 1) * (48 - 1) / 16 = 2.
			 * In GOP frame #1, top is: 1 * (48 - 1) / 16 + 1 = 3. (+ 1 since this is not the first frame)
			 * bottom is: (1 + 1) * (48 - 1) / 16 = 5.
			 * In GOP frame #2, top is: 2 * (48 - 1) / 16 + 1 = 6. (+ 1 since this is not the first frame)
			 * bottom is: (2 + 1) * (48 - 1) / 16 = 8.
			 * etc. until the last periodic IR frame, which is frame #15:
			 * top is: 15 * (48 - 1) / 16 + 1 = 45. (+ 1 since this is not the first frame)
			 * bottom is: (15 + 1) * (48 - 1) / 16 = 47.
			 */
			top = encoder->periodic_ir_frame_counter * (base->num_macroblocks_per_column - 1) / encoder->periodic_ir_total_amount;
			bottom = (encoder->periodic_ir_frame_counter + 1) * (base->num_macroblocks_per_column - 1) / encoder->periodic_ir_total_amount;

			if (encoder->periodic_ir_frame_counter > 0)
				top++;

			IMX_VPU_API_LOG(
				"periodic intra refresh: top %u bottom %u frame counter %u total frame amount %u",
				top,
				bottom,
				encoder->periodic_ir_frame_counter,
				encoder->periodic_ir_total_amount
			);

			coding_control.intraArea.enable = 1;
			coding_control.intraArea.left = 0;
			coding_control.intraArea.right = base->num_macroblocks_per_row - 1;
			coding_control.intraArea.top = top;
			coding_control.intraArea.bottom = bottom;

			/* Also make use of ROI to make sure the video quality in the
			 * intra macroblocks is closer to the one of the inter one. */

			coding_control.roi1Area.enable = 1;
			coding_control.roi1Area.left = coding_control.intraArea.left;
			coding_control.roi1Area.right = coding_control.intraArea.right;
			coding_control.roi1Area.top = coding_control.intraArea.top;
			coding_control.roi1Area.bottom = coding_control.intraArea.bottom;

			coding_control.roi1DeltaQp = -3;

			enc_ret = VP8EncSetCodingCtrl(encoder->handle, &coding_control);
			if (enc_ret != VP8ENC_OK)
			{
				IMX_VPU_API_ERROR("could not set VP8 encoder coding control setup: %s", h1_vp8_encoder_ret_to_string(enc_ret));
				return IMX_VPU_API_ENC_RETURN_CODE_ERROR;
			}

			encoder->periodic_ir_frame_counter++;

			if (encoder->periodic_ir_frame_counter >= encoder->periodic_ir_total_amount)
				encoder->periodic_ir_finished = TRUE;
		}
		else
		{
			/* During the first GOP, do not use periodic IR, since
			 * the very first GOP starts with an actual I frame.
			 * Implement this as if the first GOP's periodic IR was
			 * "finished instantly", and 0 IR frames were produced. */
			encoder->periodic_ir_finished = TRUE;
			IMX_VPU_API_DEBUG("not yet using periodic intra refresh since this is the first GOP");
		}
	}

	switch (frame_type)
	{
		case IMX_VPU_API_FRAME_TYPE_I:
		case IMX_VPU_API_FRAME_TYPE_IDR:
			encoder->input.codingType = VP8ENC_INTRA_FRAME;
			encoder->base->encoded_frame_is_sync_point = TRUE;
			break;
		case IMX_VPU_API_FRAME_TYPE_P:
		/* Interpret IMX_VPU_API_FRAME_TYPE_UNKNOWN as "user does not enforce a particular type",
		 * and in that case, default to a predicted frame. */
		case IMX_VPU_API_FRAME_TYPE_UNKNOWN:
			encoder->input.codingType = VP8ENC_PREDICTED_FRAME;
			break;
		default:
			assert(FALSE);
	}

	enc_ret = VP8EncStrmEncode(encoder->handle, &(encoder->input), &(encoder->output));

	if (enc_ret != VP8ENC_FRAME_READY)
	{
		IMX_VPU_API_ERROR("could not encode VP8 frame: %s", h1_vp8_encoder_ret_to_string(enc_ret));
		return IMX_VPU_API_ENC_RETURN_CODE_ERROR;
	}

	switch (encoder->output.codingType)
	{
		case VP8ENC_INTRA_FRAME:
			*encoded_frame_type = IMX_VPU_API_FRAME_TYPE_I;
			break;
		case VP8ENC_PREDICTED_FRAME:
			*encoded_frame_type = IMX_VPU_API_FRAME_TYPE_P;
			break;
		case VP8ENC_NOTCODED_FRAME:
			*encoded_frame_type = IMX_VPU_API_FRAME_TYPE_SKIP;
			return IMX_VPU_API_ENC_RETURN_CODE_OK;
		default:
			assert(FALSE);
	}

	/* VP8 data is spread amongst partitions that have to be accessed
	 * individually, so to get a total encoded frame size, sum them all up. */
	base->num_bytes_in_stream_buffer = 0;
	for (i = 0;  i < 9; ++i)
	{
		IMX_VPU_API_LOG("VP8 partition #%d contains %" PRIu32 " byte", i, (uint32_t)(encoder->output.streamSize[i]));
		base->num_bytes_in_stream_buffer += encoder->output.streamSize[i];
	}

	*encoded_frame_size = (base->must_prepend_header_data ? base->header_data_size : 0) + base->num_bytes_in_stream_buffer;

	encoder->gop_frame_counter++;
	encoder->is_first_frame = FALSE;

	*output_code = IMX_VPU_API_ENC_OUTPUT_CODE_ENCODED_FRAME_AVAILABLE;

	return IMX_VPU_API_ENC_RETURN_CODE_OK;
}

static void h1_vp8_get_encoded_data(void *h1_encoder, ImxVpuApiEncodedFrame *encoded_frame)
{
	int i;
	H1VP8Encoder *encoder = (H1VP8Encoder *)h1_encoder;
	ImxVpuApiEncoder *base = encoder->base;
	uint8_t *encoded_data = encoded_frame->data;

	if (base->must_prepend_header_data)
	{
		memcpy(encoded_data, base->header_data, base->header_data_size);
		encoded_data += base->header_data_size;
		base->must_prepend_header_data = FALSE;
	}

	/* Begin synced access since we have to copy the encoded
	 * data out of the stream buffer. */
	imx_dma_buffer_start_sync_session(base->stream_buffer);

	for (i = 0;  i < 9; ++i)
	{
		if (encoder->output.streamSize[i] == 0)
			continue;

		memcpy(encoded_data, encoder->output.pOutBuf[i], encoder->output.streamSize[i]);
		encoded_data += encoder->output.streamSize[i];
	}

	imx_dma_buffer_stop_sync_session(base->stream_buffer);
}

static void h1_vp8_flush(void *h1_encoder)
{
	H1VP8Encoder *encoder = (H1VP8Encoder *)h1_encoder;
	encoder->is_first_frame = TRUE;
	encoder->gop_frame_counter = 0;
	encoder->periodic_ir_finished = FALSE;
	encoder->periodic_ir_frame_counter = 0;
}

static char const * h1_vp8_encoder_ret_to_string(VP8EncRet enc_ret)
{
	switch (enc_ret)
	{
		case VP8ENC_OK: return "ok";
		case VP8ENC_FRAME_READY: return "frame ready";
		case VP8ENC_ERROR: return "error";
		case VP8ENC_NULL_ARGUMENT: return "null argument";
		case VP8ENC_INVALID_ARGUMENT: return "invalid argument";
		case VP8ENC_MEMORY_ERROR: return "memory error";
		case VP8ENC_EWL_ERROR: return "EWL error";
		case VP8ENC_EWL_MEMORY_ERROR: return "EWL memory error";
		case VP8ENC_INVALID_STATUS: return "invalid status";
		case VP8ENC_OUTPUT_BUFFER_OVERFLOW: return "output buffer overflow";
		case VP8ENC_HW_BUS_ERROR: return "hardware bus error";
		case VP8ENC_HW_DATA_ERROR: return "hardware data error";
		case VP8ENC_HW_TIMEOUT: return "hardware timeout";
		case VP8ENC_HW_RESERVED: return "hardware reserved";
		case VP8ENC_SYSTEM_ERROR: return "system error";
		case VP8ENC_INSTANCE_ERROR: return "instance error";
		case VP8ENC_HRD_ERROR: return "HRD error";
		case VP8ENC_HW_RESET: return "hardware reset";
		default: return "<unknown>";
	}
}

static char const * h1_vp8_encoder_interpolation_filter_to_string(uint32_t filter)
{
	switch (filter)
	{
		case 0: return "bicubic";
		case 1: return "bilinear";
		case 2: return "none";
		default: return "<unknown>";
	}
}

static char const * h1_vp8_encoder_deblocking_loop_filter_type_to_string(uint32_t filter_type)
{
	switch (filter_type)
	{
		case 0: return "normal";
		case 1: return "simple";
		default: return "<unknown>";
	}
}

static char const * h1_vp8_encoder_quality_metric_to_string(uint32_t metric)
{
	switch (metric)
	{
		case VP8ENC_QM_PSNR: return "PSNR";
		case VP8ENC_QM_SSIM: return "SSIM";
		default: return "<unknown>";
	}
}



/****************************************************************/
/******* HANTRO H1 h.264 ENCODER STRUCTURES AND FUNCTIONS *******/
/****************************************************************/


static ImxVpuApiEncReturnCodes h1_h264_open_encoder(ImxVpuApiEncoder *base, void **h1_encoder);
static void h1_h264_close_encoder(void *h1_encoder);

static ImxVpuApiEncReturnCodes h1_h264_start_stream(void *h1_encoder, size_t *output_size);

static ImxVpuApiEncReturnCodes h1_h264_encode_frame(void *h1_encoder, ImxVpuApiFrameType frame_type, size_t *encoded_frame_size, ImxVpuApiFrameType *encoded_frame_type, ImxVpuApiEncOutputCodes *output_code);
static void h1_h264_get_encoded_data(void *h1_encoder, ImxVpuApiEncodedFrame *encoded_frame);

static void h1_h264_flush(void *h1_encoder);

static char const * h1_h264_encoder_ret_to_string(H264EncRet enc_ret);
static char const * h1_h264_encoder_deblocking_filter_mode_to_string(uint32_t mode);
static char const * h1_h264_encoder_calvc_cabac_usage_to_string(uint32_t cavlc_cabac_usage);
static char const * h1_h264_encoder_8x8_transform_usage_to_string(uint32_t transform_usage);

static HantroH1EncoderFunctions const h1_h264_encoder_functions = {
	.open_encoder = h1_h264_open_encoder,
	.close_encoder = h1_h264_close_encoder,

	.start_stream = h1_h264_start_stream,

	.encode_frame = h1_h264_encode_frame,
	.get_encoded_data = h1_h264_get_encoded_data,

	.flush = h1_h264_flush,
};

typedef struct
{
	ImxVpuApiEncoder *base;
	H264EncInst handle;
	H264EncIn input;
	BOOL is_first_frame;
	unsigned int gop_frame_counter;
	unsigned int interval_between_idr_frames;
}
H1H264Encoder;

static ImxVpuApiEncReturnCodes h1_h264_open_encoder(ImxVpuApiEncoder *base, void **h1_encoder)
{
	ImxVpuApiEncReturnCodes ret = IMX_VPU_API_ENC_RETURN_CODE_OK;
	ImxVpuApiEncOpenParams *open_params;
	ImxVpuApiFramebufferMetrics *fb_metrics;
	ImxVpuApiH264Level level;
	H1H264Encoder *encoder = NULL;
	H264EncConfig config;
	H264EncApiVersion api_version;
	H264EncBuild encoder_build;
	H264EncCodingCtrl coding_control;
	H264EncRateCtrl rate_control;
	H264EncPreProcessingCfg preprocessor_config;
	H264EncRet enc_ret;

	assert(base != NULL);
	assert(h1_encoder != NULL);


	/* Initial preparations */

	encoder = malloc(sizeof(H1H264Encoder));
	assert(encoder != NULL);

	open_params = &(base->open_params);
	fb_metrics = &(base->stream_info.frame_encoding_framebuffer_metrics);

	encoder->base = base;

	/* Closed GOP intervals are emulated by forcing IDR keyframes at specific intervals. */
	encoder->interval_between_idr_frames = open_params->closed_gop_interval * open_params->gop_size;

	base->stream_info.format_specific_open_params.h264_open_params = open_params->format_specific_open_params.h264_open_params;

	/* Estimate the max level if none is specified. The H1
	 * encoder requires the level to be set to a valid value. */
	if (open_params->format_specific_open_params.h264_open_params.level == IMX_VPU_API_H264_LEVEL_UNDEFINED)
	{
		level = imx_vpu_api_estimate_max_h264_level(
			fb_metrics->aligned_frame_width, fb_metrics->aligned_frame_height,
			open_params->bitrate,
			open_params->frame_rate_numerator,
			open_params->frame_rate_denominator,
			open_params->format_specific_open_params.h264_open_params.profile
		);
		IMX_VPU_API_DEBUG(
			"no h.264 level given; estimated level %s out of width, height, bitrate, framerate, profile",
			imx_vpu_api_h264_level_string(level)
		);
		base->stream_info.format_specific_open_params.h264_open_params.level = level;
	}
	else
		level = open_params->format_specific_open_params.h264_open_params.level;

	api_version = H264EncGetApiVersion();
	encoder_build = H264EncGetBuild();
	IMX_VPU_API_INFO(
		"Hantro H1 h.264 encoder API version %d.%d hardware ID %c%c 0x%08x software build %d.%d.%d",
		(int)(api_version.major), (int)(api_version.minor),
		(char)((encoder_build.hwBuild >> 24) & 0xFF), (char)((encoder_build.hwBuild>>16) & 0xFF),
		(uint32_t)(encoder_build.hwBuild),
		(int)(encoder_build.swBuild / 1000000), (int)((encoder_build.swBuild / 1000) % 1000), (int)(encoder_build.swBuild % 1000)
	);


	/* Basic encoder configuration and initialization */

	memset(&config, 0, sizeof(config));
	config.streamType = H264ENC_BYTE_STREAM;
	config.viewMode = H264ENC_BASE_VIEW_DOUBLE_BUFFER;
	config.width = fb_metrics->aligned_frame_width;
	config.height = fb_metrics->aligned_frame_height;
	config.frameRateNum = open_params->frame_rate_numerator;
	config.frameRateDenom = open_params->frame_rate_denominator;
	config.scaledWidth = 0;
	config.scaledHeight = 0;
	config.refFrameAmount = 1;
	config.refFrameCompress = 0;
	config.rfcLumBufLimit = 0;
	config.rfcChrBufLimit = 0;
	config.svctLevel = 0;

	switch (level)
	{
		case IMX_VPU_API_H264_LEVEL_1: config.level = H264ENC_LEVEL_1; break;
		case IMX_VPU_API_H264_LEVEL_1B: config.level = H264ENC_LEVEL_1_b; break;
		case IMX_VPU_API_H264_LEVEL_1_1: config.level = H264ENC_LEVEL_1_1; break;
		case IMX_VPU_API_H264_LEVEL_1_2: config.level = H264ENC_LEVEL_1_2; break;
		case IMX_VPU_API_H264_LEVEL_1_3: config.level = H264ENC_LEVEL_1_3; break;
		case IMX_VPU_API_H264_LEVEL_2: config.level = H264ENC_LEVEL_2; break;
		case IMX_VPU_API_H264_LEVEL_2_1: config.level = H264ENC_LEVEL_2_1; break;
		case IMX_VPU_API_H264_LEVEL_2_2: config.level = H264ENC_LEVEL_2_2; break;
		case IMX_VPU_API_H264_LEVEL_3: config.level = H264ENC_LEVEL_3; break;
		case IMX_VPU_API_H264_LEVEL_3_1: config.level = H264ENC_LEVEL_3_1; break;
		case IMX_VPU_API_H264_LEVEL_3_2: config.level = H264ENC_LEVEL_3_2; break;
		case IMX_VPU_API_H264_LEVEL_4: config.level = H264ENC_LEVEL_4; break;
		case IMX_VPU_API_H264_LEVEL_4_1: config.level = H264ENC_LEVEL_4_1; break;
		case IMX_VPU_API_H264_LEVEL_4_2: config.level = H264ENC_LEVEL_4_2; break;
		case IMX_VPU_API_H264_LEVEL_5: config.level = H264ENC_LEVEL_5; break;
		case IMX_VPU_API_H264_LEVEL_5_1: config.level = H264ENC_LEVEL_5_1; break;
		default:
			IMX_VPU_API_ERROR("unknown/unsupported h.264 level %s", imx_vpu_api_h264_level_string(level));
			ret = IMX_VPU_API_ENC_RETURN_CODE_UNSUPPORTED_COMPRESSION_FORMAT_PARAMS;
			goto error;
	}

	enc_ret = H264EncInit(&config, &(encoder->handle));
	if (enc_ret != H264ENC_OK)
	{
		IMX_VPU_API_ERROR("could not initialize h.264 encoder: %s", h1_h264_encoder_ret_to_string(enc_ret));
		if (enc_ret == H264ENC_INVALID_ARGUMENT)
			ret = IMX_VPU_API_ENC_RETURN_CODE_INVALID_PARAMS;
		goto error;
	}


	/* Coding control setup */

	/* Get the defaults */
	memset(&coding_control, 0, sizeof(coding_control));
	enc_ret = H264EncGetCodingCtrl(encoder->handle, &coding_control);
	if (enc_ret != H264ENC_OK)
	{
		IMX_VPU_API_ERROR("could not get default h.264 encoder coding control setup: %s", h1_h264_encoder_ret_to_string(enc_ret));
		goto error;
	}

	/* Encode the entire picture in one slice */
	coding_control.sliceSize = 0;
	coding_control.seiMessages = 0;
	/* Make sure SPS and PPS NALUs are prepended to IDR frames to
	 * facilitate seeking as well as allowing the use of the
	 * encoded stream even in the middle of streaming (for example,
	 * because someone just started watching an h.264 live stream). */
	coding_control.idrHeader = 1;
	coding_control.videoFullRange = (open_params->flags & IMX_VPU_API_ENC_H264_OPEN_PARAMS_FLAG_FULL_VIDEO_RANGE) ? 1 : 0;
	/* Don't constrain the intra prediction */
	coding_control.constrainedIntraPrediction = 0;
	/* 0 = deblocking filter enabled */
	coding_control.disableDeblockingFilter = 0;
	/* Don't specify sample aspect ratio
	 * (that information is not available here) */
	coding_control.sampleAspectRatioWidth = 0;
	coding_control.sampleAspectRatioHeight = 0;
	/* Adaptive quarter pixel motion estimation */
	coding_control.quarterPixelMv = 1;
	/* Configure gradual decoder refresh (GDR), a method for implementing
	 * intra refresh functionality. It is a good idea to enable intra
	 * refresh that way, since the underlying Hantro code then fills in
	 * h.264 SPS/PPS NALUs, SEI messages etc. with appropriate extra info.
	 * This is something that otherwise would have to be done manually. */
	coding_control.gdrDuration = base->use_intra_refresh ? open_params->gop_size : 0;
	/* Don't force any slices to be intra-coded */
	coding_control.intraSliceMap1 = 0;
	coding_control.intraSliceMap2 = 0;
	coding_control.intraSliceMap3 = 0;
	/* Disable intra and ROI areas
	 * NOTE: If GDR is active, the driver may decide to enable some of these
	 * on its own. Any future attempts to enable these areas here must not be
	 * done while GDR is enabled (except for ROI2, which the driver does not
	 * seem to use for GDR). */
	coding_control.intraArea.enable = 0;
	coding_control.roi1Area.enable = 0;
	coding_control.roi2Area.enable = 0;

	IMX_VPU_API_DEBUG("using GOP size %u as Gradual Decoder Refresh (GDR) interval for intra refresh", open_params->gop_size);

	switch (open_params->format_specific_open_params.h264_open_params.profile)
	{
		case IMX_VPU_API_H264_PROFILE_CONSTRAINED_BASELINE:
			coding_control.enableCabac = 0;
			coding_control.transform8x8Mode = 0;
			break;
		case IMX_VPU_API_H264_PROFILE_MAIN:
			coding_control.enableCabac = 1;
			coding_control.transform8x8Mode = 0;
			break;
		case IMX_VPU_API_H264_PROFILE_HIGH:
			coding_control.enableCabac = 1;
			/* Use adaptive 8x8, meaning that the encoder can switch
			 * between 4x4 and 8x8 per macroblock. This feature is
			 * not available in baseline and main profiles.
			 * (0 = no 8x8, 1 = adaptive 8x8, 2 = always 8x8) */
			coding_control.transform8x8Mode = 1;
			break;
		default:
			IMX_VPU_API_ERROR("unknown/unsupported h.264 profile %s", imx_vpu_api_h264_profile_string(open_params->format_specific_open_params.h264_open_params.profile));
			ret = IMX_VPU_API_ENC_RETURN_CODE_UNSUPPORTED_COMPRESSION_FORMAT_PARAMS;
			goto error;
	}

	IMX_VPU_API_DEBUG("h.264 coding control setup:");
	IMX_VPU_API_DEBUG("  slice size (in macroblock rows): %" PRIu32, (uint32_t)(coding_control.sliceSize));
	IMX_VPU_API_DEBUG("  SEI messages: %s (%" PRIu32 ")", imx_vpu_api_h1_encoder_2state_mode_to_string(coding_control.seiMessages), (uint32_t)(coding_control.seiMessages));
	IMX_VPU_API_DEBUG("  inserting SPS/PPS before IDR frames: %s (%" PRIu32 ")", imx_vpu_api_h1_encoder_2state_mode_to_string(coding_control.idrHeader), (uint32_t)(coding_control.idrHeader));
	IMX_VPU_API_DEBUG("  full 0-255 range: %s (%" PRIu32 ")", imx_vpu_api_h1_encoder_2state_mode_to_string(coding_control.videoFullRange), (uint32_t)(coding_control.videoFullRange));
	IMX_VPU_API_DEBUG("  constrained intra prediction: %s", coding_control.constrainedIntraPrediction ? "no constraints" : "only use intra neighbours");
	IMX_VPU_API_DEBUG("  disable deblocking filter: %s (%" PRIu32 ")", h1_h264_encoder_deblocking_filter_mode_to_string(coding_control.disableDeblockingFilter), (uint32_t)(coding_control.disableDeblockingFilter));
	IMX_VPU_API_DEBUG("  sample aspect ratio width: %" PRIu32, (uint32_t)(coding_control.sampleAspectRatioWidth));
	IMX_VPU_API_DEBUG("  sample aspect ratio height: %" PRIu32, (uint32_t)(coding_control.sampleAspectRatioHeight));
	IMX_VPU_API_DEBUG("  CAVLC/CABAC usage: %s (%" PRIu32 ")", h1_h264_encoder_calvc_cabac_usage_to_string(coding_control.enableCabac), (uint32_t)(coding_control.enableCabac));
	IMX_VPU_API_DEBUG("  CABAC initial IDC: %" PRIu32, (uint32_t)(coding_control.cabacInitIdc));
	IMX_VPU_API_DEBUG("  8x8 transform usage: %s (%" PRIu32 ")", h1_h264_encoder_8x8_transform_usage_to_string(coding_control.transform8x8Mode), (uint32_t)(coding_control.transform8x8Mode));
	IMX_VPU_API_DEBUG("  quarter pixel motion estimation: %" PRIu32, (uint32_t)(coding_control.quarterPixelMv));
	IMX_VPU_API_DEBUG("  forced 0-31 slice intra bitmap: %" PRIu32, (uint32_t)(coding_control.intraSliceMap1));
	IMX_VPU_API_DEBUG("  forced 32-63 slice intra bitmap: %" PRIu32, (uint32_t)(coding_control.intraSliceMap2));
	IMX_VPU_API_DEBUG("  forced 64-95 slice intra bitmap: %" PRIu32, (uint32_t)(coding_control.intraSliceMap3));
	IMX_VPU_API_DEBUG("  forced intra macroblock area: enabled: %" PRIu32 " left/top/right/bottom: %" PRIu32 "/%" PRIu32 "/%" PRIu32 "/%" PRIu32,
		(uint32_t)(coding_control.intraArea.enable),
		(uint32_t)(coding_control.intraArea.left),
		(uint32_t)(coding_control.intraArea.top),
		(uint32_t)(coding_control.intraArea.right),
		(uint32_t)(coding_control.intraArea.bottom)
	);
	IMX_VPU_API_DEBUG("  forced ROI 1 macroblock area: enabled: %" PRIu32 " left/top/right/bottom: %" PRIu32 "/%" PRIu32 "/%" PRIu32 "/%" PRIu32,
		(uint32_t)(coding_control.roi1Area.enable),
		(uint32_t)(coding_control.roi1Area.left),
		(uint32_t)(coding_control.roi1Area.top),
		(uint32_t)(coding_control.roi1Area.right),
		(uint32_t)(coding_control.roi1Area.bottom)
	);
	IMX_VPU_API_DEBUG("  forced ROI 2 macroblock area: enabled: %" PRIu32 " left/top/right/bottom: %" PRIu32 "/%" PRIu32 "/%" PRIu32 "/%" PRIu32,
		(uint32_t)(coding_control.roi2Area.enable),
		(uint32_t)(coding_control.roi2Area.left),
		(uint32_t)(coding_control.roi2Area.top),
		(uint32_t)(coding_control.roi2Area.right),
		(uint32_t)(coding_control.roi2Area.bottom)
	);
	IMX_VPU_API_DEBUG("  ROI 1 delta QP: %" PRId32, (int32_t)(coding_control.roi1DeltaQp));
	IMX_VPU_API_DEBUG("  ROI 2 delta QP: %" PRId32, (int32_t)(coding_control.roi2DeltaQp));
	IMX_VPU_API_DEBUG("  adaptive ROI QP delta: %" PRId32, (int32_t)(coding_control.adaptiveRoi));
	IMX_VPU_API_DEBUG("  adaptive ROI temperature sensitivity (in Kelvin): %" PRId32, (int32_t)(coding_control.adaptiveRoiColor));
	IMX_VPU_API_DEBUG("  ROI map: enabled: %" PRId32 " QP offsets: %" PRId32 " %" PRId32 " %" PRId32,
		(int32_t)(coding_control.roiMapEnable),
		(int32_t)(coding_control.qpOffset[0]),
		(int32_t)(coding_control.qpOffset[1]),
		(int32_t)(coding_control.qpOffset[2])
	);
	IMX_VPU_API_DEBUG("  interlacing field order: %s", coding_control.fieldOrder ? "top field first" : "bottom field first");
	IMX_VPU_API_DEBUG("  GDR duration: %" PRIu32, (int32_t)(coding_control.gdrDuration));
	IMX_VPU_API_DEBUG("  SVC temporal scalable coding, max number of layers: %" PRIu32, (int32_t)(coding_control.svctLevel));
	IMX_VPU_API_DEBUG("  Wiener denoise filter:");
	IMX_VPU_API_DEBUG("    enabled: %" PRIu32, (int32_t)(coding_control.noiseReductionEnable));
	IMX_VPU_API_DEBUG("    noise low: %" PRIu32, (int32_t)(coding_control.noiseLow));
	IMX_VPU_API_DEBUG("    noise level: %" PRIu32, (int32_t)(coding_control.noiseLevel));

	enc_ret = H264EncSetCodingCtrl(encoder->handle, &coding_control);
	if (enc_ret != H264ENC_OK)
	{
		IMX_VPU_API_ERROR("could not set h.264 encoder coding control setup: %s", h1_h264_encoder_ret_to_string(enc_ret));
		if (enc_ret == H264ENC_INVALID_ARGUMENT)
			ret = IMX_VPU_API_ENC_RETURN_CODE_INVALID_PARAMS;
		goto error;
	}


	/* Rate control setup */

	/* Get the defaults */
	memset(&rate_control, 0, sizeof(rate_control));
	enc_ret = H264EncGetRateCtrl(encoder->handle, &rate_control);
	if (enc_ret != H264ENC_OK)
	{
		IMX_VPU_API_ERROR("could not get default h.264 encoder rate control setup: %s", h1_h264_encoder_ret_to_string(enc_ret));
		goto error;
	}

	rate_control.qpMin = 0;
	rate_control.qpMax = 51;
	rate_control.bitPerSecond = open_params->bitrate * 1000;
	rate_control.gopLen = open_params->gop_size;

	if (open_params->bitrate != 0)
	{
		int fixed_intra_qp = open_params->fixed_intra_quantization;

		rate_control.pictureRc = 1;
		rate_control.mbRc = 1;
		rate_control.pictureSkip = (open_params->flags & IMX_VPU_API_ENC_OPEN_PARAMS_FLAG_ALLOW_FRAMESKIPPING) ? 1 : 0;
		rate_control.qpHdr = -1; /* -1 = Let rate control calculate initial QP */
		rate_control.hrd = 1; /* enable the Hypothetical Reference Decoder model */
		rate_control.fixedIntraQp = (fixed_intra_qp > 0) ? fixed_intra_qp : 0; /* 0 = rate control calculates intra QP */
	}
	else
	{
		rate_control.pictureRc = 0;
		rate_control.mbRc = 0;
		rate_control.pictureSkip = 0;
		rate_control.qpHdr = open_params->quantization;
		rate_control.hrd = 0;
		rate_control.fixedIntraQp = open_params->quantization;
	}

	IMX_VPU_API_DEBUG("h.264 rate control setup:");
	IMX_VPU_API_DEBUG("  QP rate control between pictures: %" PRIu32, (uint32_t)(rate_control.pictureRc));
	IMX_VPU_API_DEBUG("  QP rate control inside picture: %" PRIu32, (uint32_t)(rate_control.mbRc));
	IMX_VPU_API_DEBUG("  allow rate control to skip pictures: %" PRIu32, (uint32_t)(rate_control.pictureSkip));
	IMX_VPU_API_DEBUG("  QP for next picture: %" PRId32, (int32_t)(rate_control.qpHdr));
	IMX_VPU_API_DEBUG("  bits per second: %" PRIu32, (uint32_t)(rate_control.bitPerSecond));
	IMX_VPU_API_DEBUG("  Hypothetical Reference Decoder model enabled: %s (%" PRIu32 ")", imx_vpu_api_h1_encoder_2state_mode_to_string(rate_control.hrd), (uint32_t)(rate_control.hrd));
	IMX_VPU_API_DEBUG("  Hypothetical Reference Decoder model CPB size: %" PRIu32, (uint32_t)(rate_control.hrdCpbSize));
	IMX_VPU_API_DEBUG("  GOP length: %" PRIu32, (uint32_t)(rate_control.gopLen));
	IMX_VPU_API_DEBUG("  intra QP delta: %" PRId32, (int32_t)(rate_control.intraQpDelta));

	if (rate_control.fixedIntraQp == 0)
		IMX_VPU_API_DEBUG("  fixed intra QP: (automatically calculated based by rate control)");
	else
		IMX_VPU_API_DEBUG("  fixed intra QP: %" PRIu32, (uint32_t)(rate_control.fixedIntraQp));

	IMX_VPU_API_DEBUG("  macroblock QP adjustments: %" PRId32, (int32_t)(rate_control.mbQpAdjustment));
	IMX_VPU_API_DEBUG("  period between long term pic refreshes: %" PRId32, (int32_t)(rate_control.longTermPicRate));
	IMX_VPU_API_DEBUG("  QP auto boost: %" PRId32, (int32_t)(rate_control.mbQpAutoBoost));

	enc_ret = H264EncSetRateCtrl(encoder->handle, &rate_control);
	if (enc_ret != H264ENC_OK)
	{
		IMX_VPU_API_ERROR("could not set h.264 encoder rate control setup: %s", h1_h264_encoder_ret_to_string(enc_ret));
		if (enc_ret == H264ENC_INVALID_ARGUMENT)
			ret = IMX_VPU_API_ENC_RETURN_CODE_INVALID_PARAMS;
		goto error;
	}


	/* Preprocessor setup */

	/* Get the defaults */
	memset(&preprocessor_config, 0, sizeof(preprocessor_config));
	enc_ret = H264EncGetPreProcessing(encoder->handle, &preprocessor_config);
	if (enc_ret != H264ENC_OK)
	{
		IMX_VPU_API_ERROR("could not get default h.264 preprocessor config: %s", h1_h264_encoder_ret_to_string(enc_ret));
		goto error;
	}

	preprocessor_config.origWidth = fb_metrics->aligned_frame_width;
	preprocessor_config.origHeight = fb_metrics->aligned_frame_height;
	/* Preprocessing is (currently) not supported by the imxvpuapi encoder API */
	preprocessor_config.xOffset = 0;
	preprocessor_config.yOffset = 0;
	preprocessor_config.rotation = H264ENC_ROTATE_0;
	preprocessor_config.videoStabilization = 0;
	/* Currently, setting this through the API is not supported. Use BT.709,
	 * since that's what is used in HD video, and that is what nowadays
	 * is primarily used (BT.601 was made for old analog TV). */
	preprocessor_config.colorConversion.type = H264ENC_RGBTOYUV_BT709;
	preprocessor_config.scaledOutput = 0;
	/* Interlacing is (currently) not supported by the imxvpuapi encoder API */
	preprocessor_config.interlacedFrame = 0;

	switch (open_params->color_format)
	{
		case IMX_VPU_API_COLOR_FORMAT_FULLY_PLANAR_YUV420_8BIT:
			preprocessor_config.inputType = H264ENC_YUV420_PLANAR;
			break;
		case IMX_VPU_API_COLOR_FORMAT_SEMI_PLANAR_YUV420_8BIT:
			preprocessor_config.inputType = H264ENC_YUV420_SEMIPLANAR;
			break;
		case IMX_VPU_API_COLOR_FORMAT_PACKED_YUV422_UYVY_8BIT:
			preprocessor_config.inputType = H264ENC_YUV422_INTERLEAVED_UYVY;
			break;
		case IMX_VPU_API_COLOR_FORMAT_PACKED_YUV422_YUYV_8BIT:
			preprocessor_config.inputType = H264ENC_YUV422_INTERLEAVED_YUYV;
			break;
		case IMX_VPU_API_COLOR_FORMAT_RGB565:
			preprocessor_config.inputType = H264ENC_RGB565;
			break;
		case IMX_VPU_API_COLOR_FORMAT_BGR565:
			preprocessor_config.inputType = H264ENC_BGR565;
			break;
		case IMX_VPU_API_COLOR_FORMAT_ARGB1555:
			preprocessor_config.inputType = H264ENC_RGB555;
			break;
		case IMX_VPU_API_COLOR_FORMAT_RGB444:
		case IMX_VPU_API_COLOR_FORMAT_ARGB4444:
			preprocessor_config.inputType = H264ENC_RGB444;
			break;
		case IMX_VPU_API_COLOR_FORMAT_RGBA8888:
			preprocessor_config.inputType = H264ENC_BGR888;
			break;
		case IMX_VPU_API_COLOR_FORMAT_BGRA8888:
			preprocessor_config.inputType = H264ENC_RGB888;
			break;
		default:
			/* Invalid/unsupported color formats should already have been
			 * taken care of by the code in imx_vpu_api_enc_open(). */
			assert(FALSE);
	}

	enc_ret = H264EncSetPreProcessing(encoder->handle, &preprocessor_config);
	if (enc_ret != H264ENC_OK)
	{
		IMX_VPU_API_ERROR("could not set h.264 preprocessor config: %s", h1_h264_encoder_ret_to_string(enc_ret));
		if (enc_ret == H264ENC_INVALID_ARGUMENT)
			ret = IMX_VPU_API_ENC_RETURN_CODE_INVALID_PARAMS;
		goto error;
	}


	/* Set VUI color description */

	/* See ISO/IEC 14496-10 , E.2.1 for documentation of these values */
	enc_ret = H264EncSetVuiColorDescription(
		encoder->handle,
		0, /* vuiVideoSignalTypePresentFlag ; 1 = do not add VUI description */
		5, /* vuiVideoFormat ; 5 = unspecified video format (other options are PAL, NTSC etc.) */
		0, /* vuiColorDescripPresentFlag ; 0 = no primaries, transfer characteristics, matrix coefficients */
		0, /* vuiColorPrimaries ; set to 0 since the flag above is set to 0 */
		0, /* vuiTransferCharacteristics ; set to 0 since the flag above is set to 0 */
		0  /* vuiMatrixCoefficients ; set to 0 since the flag above is set to 0 */
	);
	if (enc_ret != H264ENC_OK)
	{
		IMX_VPU_API_ERROR("could not set h.264 VUI color description: %s", h1_h264_encoder_ret_to_string(enc_ret));
		goto error;
	}


finish:
	*h1_encoder = encoder;
	return ret;

error:
	h1_h264_close_encoder(encoder);
	encoder = NULL;
	if (ret == IMX_VPU_API_ENC_RETURN_CODE_OK)
		ret = IMX_VPU_API_ENC_RETURN_CODE_ERROR;
	goto finish;
}


static void h1_h264_close_encoder(void *h1_encoder)
{
	H1H264Encoder *encoder = (H1H264Encoder *)h1_encoder;

	if (encoder == NULL)
		return;

	if (encoder->handle != NULL)
		H264EncRelease(encoder->handle);

	free(encoder);
}


static ImxVpuApiEncReturnCodes h1_h264_start_stream(void *h1_encoder, size_t *output_size)
{
	H264EncRet enc_ret;
	H264EncOut encoder_output;
	H1H264Encoder *encoder = (H1H264Encoder *)h1_encoder;

	assert(encoder != NULL);
	assert(output_size != NULL);

	encoder->input.pOutBuf = (u32 *)(encoder->base->stream_buffer_virtual_address);
	encoder->input.busOutBuf = encoder->base->stream_buffer_physical_address;
	encoder->input.outBufSize = encoder->base->stream_buffer_size;

	enc_ret = H264EncStrmStart(encoder->handle, &(encoder->input), &encoder_output);
	if (enc_ret != H264ENC_OK)
	{
		IMX_VPU_API_ERROR("could not start h.264 stream: %s", h1_h264_encoder_ret_to_string(enc_ret));
		return IMX_VPU_API_ENC_RETURN_CODE_ERROR;
	}

	*output_size = encoder_output.streamSize;

	encoder->is_first_frame = TRUE;
	encoder->gop_frame_counter = 0;

	return IMX_VPU_API_ENC_RETURN_CODE_OK;
}


static ImxVpuApiEncReturnCodes h1_h264_encode_frame(void *h1_encoder, ImxVpuApiFrameType frame_type, size_t *encoded_frame_size, ImxVpuApiFrameType *encoded_frame_type, ImxVpuApiEncOutputCodes *output_code)
{
	H264EncRet enc_ret;
	H264EncOut encoder_output;
	H1H264Encoder *encoder = (H1H264Encoder *)h1_encoder;
	ImxVpuApiEncoder *base = encoder->base;
	ImxVpuApiFramebufferMetrics *fb_metrics = &(encoder->base->stream_info.frame_encoding_framebuffer_metrics);

	encoder->input.busLuma = (ptr_t)(base->staged_raw_frame_physical_address + fb_metrics->y_offset);
	encoder->input.busChromaU = (ptr_t)(base->staged_raw_frame_physical_address + fb_metrics->u_offset);
	encoder->input.busChromaV = (ptr_t)(base->staged_raw_frame_physical_address + fb_metrics->v_offset);
	encoder->input.timeIncrement = encoder->is_first_frame ? 0 : base->open_params.frame_rate_denominator;
	encoder->input.pOutBuf = (u32 *)(base->stream_buffer_virtual_address);
	encoder->input.busOutBuf = base->stream_buffer_physical_address;
	encoder->input.outBufSize = base->stream_buffer_size;
	encoder->input.busLumaStab = 0;
	/* By default, always predict from all available frames and refresh the last frame. */
	encoder->input.ipf = H264ENC_REFERENCE_AND_REFRESH;
	encoder->input.ltrf = H264ENC_REFERENCE;

	/* Enforce an I/IDR frame at the start of GOPs, and
	 * reset the counter, since this is a new GOP. */
	if ((encoder->gop_frame_counter % base->open_params.gop_size) == 0)
	{
		if (encoder->interval_between_idr_frames > 0)
		{
			/* If a closed GOP interval is used, only use IDR for
			 * every Nth GOP, with N = closed GOP interval. */

			if (encoder->gop_frame_counter == 0)
			{
				IMX_VPU_API_LOG("forcing this frame to be encoded as an IDR frame since it is the first one");
				frame_type = IMX_VPU_API_FRAME_TYPE_IDR;
				encoder->base->encoded_frame_is_sync_point = TRUE;
			}
			else if ((encoder->gop_frame_counter % encoder->interval_between_idr_frames) == 0)
			{
				IMX_VPU_API_LOG("forcing this frame to be encoded as an IDR frame to produce closed GOP");
				frame_type = IMX_VPU_API_FRAME_TYPE_IDR;
				encoder->gop_frame_counter = 0;
				encoder->base->encoded_frame_is_sync_point = TRUE;
			}
			else
			{
				frame_type = IMX_VPU_API_FRAME_TYPE_I;
				encoder->base->encoded_frame_is_sync_point = FALSE;
			}
		}
		else
		{
			/* If no closed GOP interval is used, treat all GOPs as
			 * closed, that is, always start them with an IDR frame. */

			frame_type = IMX_VPU_API_FRAME_TYPE_IDR;
			encoder->gop_frame_counter = 0;
			encoder->base->encoded_frame_is_sync_point = TRUE;
		}
	}
	else
		encoder->base->encoded_frame_is_sync_point = FALSE;

	switch (frame_type)
	{
		case IMX_VPU_API_FRAME_TYPE_I:
			encoder->input.codingType = H264ENC_NONIDR_INTRA_FRAME;
			break;
		case IMX_VPU_API_FRAME_TYPE_IDR:
			encoder->input.codingType = H264ENC_INTRA_FRAME;
			break;
		case IMX_VPU_API_FRAME_TYPE_P:
		/* Interpret IMX_VPU_API_FRAME_TYPE_UNKNOWN as "user does not enforce a particular type",
		 * and in that case, default to a predicted frame. */
		case IMX_VPU_API_FRAME_TYPE_UNKNOWN:
			encoder->input.codingType = H264ENC_PREDICTED_FRAME;
			break;
		default:
			assert(FALSE);
	}

	enc_ret = H264EncStrmEncode(encoder->handle, &(encoder->input), &encoder_output, NULL, NULL, NULL);

	if (enc_ret != H264ENC_FRAME_READY)
	{
		IMX_VPU_API_ERROR("could not encode h.264 frame: %s", h1_h264_encoder_ret_to_string(enc_ret));
		return IMX_VPU_API_ENC_RETURN_CODE_ERROR;
	}

	switch (encoder_output.codingType)
	{
		case H264ENC_INTRA_FRAME:
			*encoded_frame_type = IMX_VPU_API_FRAME_TYPE_IDR;
			encoder->base->encoded_frame_is_sync_point = TRUE;
			break;
		case H264ENC_NONIDR_INTRA_FRAME:
			*encoded_frame_type = IMX_VPU_API_FRAME_TYPE_I;
			break;
		case H264ENC_PREDICTED_FRAME:
			*encoded_frame_type = IMX_VPU_API_FRAME_TYPE_P;
			break;
		case H264ENC_NOTCODED_FRAME:
			*encoded_frame_type = IMX_VPU_API_FRAME_TYPE_SKIP;
			return IMX_VPU_API_ENC_RETURN_CODE_OK;
		default:
			assert(FALSE);
	}

	base->num_bytes_in_stream_buffer = encoder_output.streamSize;
	*encoded_frame_size = (base->must_prepend_header_data ? base->header_data_size : 0) + base->num_bytes_in_stream_buffer;

	encoder->is_first_frame = FALSE;
	encoder->gop_frame_counter++;

	*output_code = IMX_VPU_API_ENC_OUTPUT_CODE_ENCODED_FRAME_AVAILABLE;

	return IMX_VPU_API_ENC_RETURN_CODE_OK;
}


static void h1_h264_get_encoded_data(void *h1_encoder, ImxVpuApiEncodedFrame *encoded_frame)
{
	H1H264Encoder *encoder = (H1H264Encoder *)h1_encoder;
	ImxVpuApiEncoder *base = encoder->base;
	uint8_t *encoded_data = encoded_frame->data;

	if (base->must_prepend_header_data)
	{
		memcpy(encoded_data, base->header_data, base->header_data_size);
		encoded_data += base->header_data_size;
		base->must_prepend_header_data = FALSE;
	}

	/* Begin synced access since we have to copy the encoded
	 * data out of the stream buffer. */
	imx_dma_buffer_start_sync_session(base->stream_buffer);
	memcpy(encoded_data, base->stream_buffer_virtual_address, base->num_bytes_in_stream_buffer);
	imx_dma_buffer_stop_sync_session(base->stream_buffer);
}


static void h1_h264_flush(void *h1_encoder)
{
	H1H264Encoder *encoder = (H1H264Encoder *)h1_encoder;
	encoder->is_first_frame = TRUE;
	encoder->gop_frame_counter = 0;
}

static char const * h1_h264_encoder_ret_to_string(H264EncRet enc_ret)
{
	switch (enc_ret)
	{
		case H264ENC_OK: return "ok";
		case H264ENC_FRAME_READY: return "frame ready";
		case H264ENC_ERROR: return "error";
		case H264ENC_NULL_ARGUMENT: return "null argument";
		case H264ENC_INVALID_ARGUMENT: return "invalid argument";
		case H264ENC_MEMORY_ERROR: return "memory error";
		case H264ENC_EWL_ERROR: return "EWL error";
		case H264ENC_EWL_MEMORY_ERROR: return "EWL memory error";
		case H264ENC_INVALID_STATUS: return "invalid status";
		case H264ENC_OUTPUT_BUFFER_OVERFLOW: return "output buffer overflow";
		case H264ENC_HW_BUS_ERROR: return "hardware bus error";
		case H264ENC_HW_DATA_ERROR: return "hardware data error";
		case H264ENC_HW_TIMEOUT: return "hardware timeout";
		case H264ENC_HW_RESERVED: return "hardware reserved";
		case H264ENC_SYSTEM_ERROR: return "system error";
		case H264ENC_INSTANCE_ERROR: return "instance error";
		case H264ENC_HRD_ERROR: return "HRD error";
		case H264ENC_HW_RESET: return "hardware reset";
		default: return "<unknown>";
	}
}

static char const * h1_h264_encoder_deblocking_filter_mode_to_string(uint32_t mode)
{
	switch (mode)
	{
		case 0: return "enabled";
		case 1: return "disabled";
		case 2: return "disabled on slice edges";
		default: return "<unknown>";
	}
}

static char const * h1_h264_encoder_calvc_cabac_usage_to_string(uint32_t cavlc_cabac_usage)
{
	switch (cavlc_cabac_usage)
	{
		case 0: return "CAVLC";
		case 1: return "CABAC";
		case 2: return "CAVLC for intra frames, CABAC for inter frames";
		default: return "<unknown>";
	}
}

static char const * h1_h264_encoder_8x8_transform_usage_to_string(uint32_t transform_usage)
{
	switch (transform_usage)
	{
		case 0: return "disabled";
		case 1: return "adaptive";
		case 2: return "always";
		default: return "<unknown>";
	}
}
